{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/pierlim/PycharmProjects/sent_mining_CA\n"
     ]
    }
   ],
   "source": [
    "from os import getcwd, chdir\n",
    "import re\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.metrics import ConfusionMatrix\n",
    "from nltk.classify import NaiveBayesClassifier, MaxentClassifier\n",
    "from nltk.classify import accuracy\n",
    "from nltk.tokenize import word_tokenize as wt\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Change your path here\n",
    "fpath = getcwd()\n",
    "print(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>In my younger days when lunch choices consiste...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>After going through yelp and tripadvisor, I wa...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Ordered Sichuan Prawns and Singapore Rice Nood...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Wong Kei is one of the many options you'll fin...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>One of the worst experience in a restaurant in...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                             review  sentiment\n",
       "0       5  In my younger days when lunch choices consiste...          1\n",
       "1       3  After going through yelp and tripadvisor, I wa...         -1\n",
       "2       5  Ordered Sichuan Prawns and Singapore Rice Nood...          1\n",
       "3       3  Wong Kei is one of the many options you'll fin...         -1\n",
       "4       1  One of the worst experience in a restaurant in...         -1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/df_reviews_train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Standard Dataset to combine with scrapped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Very disappointed in the customer service. We ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I really wasn't thrilled with our meal here. T...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STAY AWAY...\\n\\nWe've been 3 times over the pa...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The food is good and the portions are large.  ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I feel bad about giving this place such a meh ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  Very disappointed in the customer service. We ...  negative\n",
       "1  I really wasn't thrilled with our meal here. T...  negative\n",
       "2  STAY AWAY...\\n\\nWe've been 3 times over the pa...  negative\n",
       "3  The food is good and the portions are large.  ...  negative\n",
       "4  I feel bad about giving this place such a meh ...  negative"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffile1 = open(\"./data/train.csv\",\"r\", encoding = \"ISO-8859-1\")\n",
    "df_standard = pd.read_csv(ffile1, encoding = \"utf-8\")\n",
    "df_standard.drop(['restaurant_id', 'date', 'review_id', 'stars'], inplace=True, axis=1)\n",
    "df_standard.rename(columns={'text': 'review', 'Sentiment': 'sentiment'}, inplace=True)\n",
    "df_standard.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Very disappointed in the customer service. We ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I really wasn't thrilled with our meal here. T...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STAY AWAY...\\n\\nWe've been 3 times over the pa...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The food is good and the portions are large.  ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I feel bad about giving this place such a meh ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  Very disappointed in the customer service. We ...        -1\n",
       "1  I really wasn't thrilled with our meal here. T...        -1\n",
       "2  STAY AWAY...\\n\\nWe've been 3 times over the pa...        -1\n",
       "3  The food is good and the portions are large.  ...        -1\n",
       "4  I feel bad about giving this place such a meh ...        -1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = df_standard.sentiment == 'negative'\n",
    "column_name = 'sentiment'\n",
    "df_standard.loc[mask, column_name] = -1\n",
    "mask = df_standard.sentiment == 'positive'\n",
    "column_name = 'sentiment'\n",
    "df_standard.loc[mask, column_name] = 1\n",
    "\n",
    "df_standard.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data into Train and Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In my younger days when lunch choices consiste...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>After going through yelp and tripadvisor, I wa...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ordered Sichuan Prawns and Singapore Rice Nood...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wong Kei is one of the many options you'll fin...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>One of the worst experience in a restaurant in...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  In my younger days when lunch choices consiste...          1\n",
       "1  After going through yelp and tripadvisor, I wa...         -1\n",
       "2  Ordered Sichuan Prawns and Singapore Rice Nood...          1\n",
       "3  Wong Kei is one of the many options you'll fin...         -1\n",
       "4  One of the worst experience in a restaurant in...         -1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train-Test Split + Stratify\n",
    "df.drop(['rating'], inplace=True, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df,stratify=df['sentiment'], test_size=0.3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train and df_standard are now the same format, we can concat and use it as a whole \n",
    "df_train_all = pd.concat([df_train, df_standard], axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dictionary format because apparently NLTK requires this\n",
    "train_pos = [[row[\"review\"], 1] for idx, row in df_train.iterrows() if row[\"sentiment\"]==1]\n",
    "train_neg = [[row[\"review\"], -1] for idx, row in df_train.iterrows() if row[\"sentiment\"]==-1]\n",
    "\n",
    "test_pos = [[row[\"review\"], 1] for idx, row in df_test.iterrows() if row[\"sentiment\"]==1]\n",
    "test_neg = [[row[\"review\"], -1] for idx, row in df_test.iterrows() if row[\"sentiment\"]==-1]\n",
    "\n",
    "def word_feats(words):\n",
    "    return dict([(word, True) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need this part for max ent portion\n",
    "testset = test_pos + test_neg\n",
    "test_nolab = [t[0] for t in testset]\n",
    "test_lab = [t[1] for t in testset]\n",
    "test_tokenized = [[wt(x), c] for x,c in testset]\n",
    "test_featureset = [(word_feats(d), c) for (d,c) in test_tokenized] \n",
    "test_nolab_tok = [t[0] for t in test_featureset]  # need to transform to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = train_pos + train_neg\n",
    "train_tokenized = [[wt(x), c] for x,c in trainset] # may need to introduce some pre-processing at this stage for better results\n",
    "\n",
    "def word_feats(words):\n",
    "    return dict([(word, True) for word in words])\n",
    "train_featureset = [(word_feats(d), c) for (d,c) in train_tokenized] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a combined training dataset of both scraped reviews and lecturer's standard set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_pos = [[row[\"review\"], 1] for idx, row in df_train_all.iterrows() if row[\"sentiment\"]==1]\n",
    "train_all_neg = [[row[\"review\"], -1] for idx, row in df_train_all.iterrows() if row[\"sentiment\"]==-1]\n",
    "trainset_all = train_all_pos + train_all_neg\n",
    "train_all_tokenized = [[wt(x), c] for x,c in trainset_all] # may need to introduce some pre-processing at this stage for better results\n",
    "train_all_featureset = [(word_feats(d), c) for (d,c) in train_all_tokenized] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                 refused = True               -1 : 1      =     24.0 : 1.0\n",
      "                horrible = True               -1 : 1      =     20.1 : 1.0\n",
      "                     Meh = True               -1 : 1      =     19.4 : 1.0\n",
      "                     ok. = True               -1 : 1      =     18.5 : 1.0\n",
      "               tasteless = True               -1 : 1      =     17.1 : 1.0\n",
      "               overrated = True               -1 : 1      =     17.1 : 1.0\n",
      "               happening = True               -1 : 1      =     17.1 : 1.0\n",
      "                lukewarm = True               -1 : 1      =     17.1 : 1.0\n",
      "                 Average = True               -1 : 1      =     17.1 : 1.0\n",
      "                   worst = True               -1 : 1      =     16.7 : 1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred</th>\n",
       "      <th>-1</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actuals</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>50</td>\n",
       "      <td>858</td>\n",
       "      <td>908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3113</td>\n",
       "      <td>3113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>50</td>\n",
       "      <td>3971</td>\n",
       "      <td>4021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred     -1     1   All\n",
       "actuals                \n",
       "-1       50   858   908\n",
       "1         0  3113  3113\n",
       "All      50  3971  4021"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Naive Bayes Rule using nltk\n",
    "classifier_nb = NaiveBayesClassifier.train(train_featureset)\n",
    "#print(\"Accuracy :\" +str(accuracy(classifier_nb, test_featureset)))\n",
    "classifier_nb.show_most_informative_features(10)\n",
    "\n",
    "## Preparing the data first \n",
    "train_nolab = [t[0] for t in trainset]\n",
    "train_lab = [t[1] for t in trainset]\n",
    "\n",
    "# Preparing test set in same format\n",
    "testset = test_pos + test_neg\n",
    "test_nolab = [t[0] for t in testset]\n",
    "test_lab = [t[1] for t in testset]\n",
    "\n",
    "# Create your tf-idf function\n",
    "vectorizer = TfidfVectorizer(max_df=0.7, min_df=3, use_idf=True) # modified this\n",
    "train_vectors = vectorizer.fit_transform(train_nolab)\n",
    "test_vectors = vectorizer.transform(test_nolab)\n",
    "\n",
    "## train Naive Bayes Rule using sklearn\n",
    "clf = MultinomialNB().fit(train_vectors, train_lab)\n",
    "\n",
    "predNB = clf.predict(train_vectors)\n",
    "pred = list(predNB)\n",
    "cm1=pd.crosstab( pd.Series(train_lab), pd.Series(pred), rownames= ['actuals'], colnames=['pred'],margins=True)\n",
    "cm1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5517</th>\n",
       "      <td>Had Lunch here yesterday afternoon with friend...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2369</th>\n",
       "      <td>Very good and expensive Indian restaurant. \\nP...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>Hands down the best roast duck in London, it's...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>If you're looking for the closest thing to aut...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2766</th>\n",
       "      <td>I have become a fairly regular customer at the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>One of my favourite spots to eat in London. I'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4569</th>\n",
       "      <td>Came for breakfast . Bacon and egg  naan. Yum....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4561</th>\n",
       "      <td>Excellent! Everything: food, service, and ambi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>Slow service with many mistakes - during a slo...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>So the whole entrance experience is pretty ama...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>4 out of 6 dishes were remarkable, best i've h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3215</th>\n",
       "      <td>Lovely location, its a hidden gem and a lot be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5074</th>\n",
       "      <td>Dishoom is di-licious. Go and see for yourself...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4196</th>\n",
       "      <td>Just found this place by accident. What a find...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>I was taken here recently, specifically to be ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>I wasn't that impressed when I went to the Cov...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>I was in Soho with a friend planning to eat at...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>After a long flight , and navigating out of th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3426</th>\n",
       "      <td>I don't usually eat japanese food in chinatown...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548</th>\n",
       "      <td>I have to confirm that their roast duck Canton...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3204</th>\n",
       "      <td>I went here on a recent trip to London.  Absol...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>this place will blow your mind in two ways.\\n1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5041</th>\n",
       "      <td>I've only been here for breakfast, which is th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>When this place first opened-up, I wasn't sure...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1631</th>\n",
       "      <td>A run of the mill 3* from me for Ping Pong Sou...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3522</th>\n",
       "      <td>Tokyo Diner is such a relaxed spot. It is styl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3386</th>\n",
       "      <td>I really like this place. It's cheap and cheer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3491</th>\n",
       "      <td>Maybe it was an off night, but I did not have ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5489</th>\n",
       "      <td>So amazing! Great food great service! This pla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3990</th>\n",
       "      <td>I stumbled in here when looking for somewhere ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>Was the first dim sum place I ever went to so ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2252</th>\n",
       "      <td>Tried their house specialty chicken , the stew...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>Average. The ramen is decent, but far from imp...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2346</th>\n",
       "      <td>The food was fine, but if you are a tourist, c...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>Cool spot. Great service and experience.  Dump...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4171</th>\n",
       "      <td>My brother- and sister-in-law brought me to th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3217</th>\n",
       "      <td>Nothing short of amazing ate here twice while ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3085</th>\n",
       "      <td>Why I ended up at Roti Chai is the perfect exa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3125</th>\n",
       "      <td>Such a great place!! I ate at their street foo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3344</th>\n",
       "      <td>U can't find anything nicer tha Nobu! I have t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4035</th>\n",
       "      <td>I loved the New York version of this restauran...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>Hearing reviews that this place was known for ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3679</th>\n",
       "      <td>Tasty French food at a reasonable price. It wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4970</th>\n",
       "      <td>The hype is real. There was an hour long wait ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4086</th>\n",
       "      <td>Nice ambiance, great service, but definitely o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4370</th>\n",
       "      <td>Firstly I would like to say it's the best rame...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>I've always loved Indian food and I've been to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>Never in the history of Dim Sum have such smal...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4492</th>\n",
       "      <td>What a lunch feast to remember! Came here with...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>I was not impressed with the broth. I don't se...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2655</th>\n",
       "      <td>Let me say that I'm a big ramen fan, but I thi...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2517</th>\n",
       "      <td>I've never had ramen before but boy was I miss...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4617</th>\n",
       "      <td>A fantastic and different place for breakfast ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2710</th>\n",
       "      <td>Authentic and Nice atmosphere. Friendly servic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>This place is a treat if you love dim sum. I w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>Clos Maggiore in Covent Garden had excellent s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2962</th>\n",
       "      <td>This restaurant is not good for families . Whe...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4813</th>\n",
       "      <td>I had brunch here. Beware that brunch is until...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>Super modern setting, delicious food. The lych...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>I like the price the most.. AND the food is pr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4021 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review  sentiment\n",
       "5517  Had Lunch here yesterday afternoon with friend...          1\n",
       "2369  Very good and expensive Indian restaurant. \\nP...          1\n",
       "1464  Hands down the best roast duck in London, it's...          1\n",
       "297   If you're looking for the closest thing to aut...          1\n",
       "2766  I have become a fairly regular customer at the...          1\n",
       "949   One of my favourite spots to eat in London. I'...          1\n",
       "4569  Came for breakfast . Bacon and egg  naan. Yum....          1\n",
       "4561  Excellent! Everything: food, service, and ambi...          1\n",
       "454   Slow service with many mistakes - during a slo...         -1\n",
       "566   So the whole entrance experience is pretty ama...          1\n",
       "1238  4 out of 6 dishes were remarkable, best i've h...          1\n",
       "3215  Lovely location, its a hidden gem and a lot be...          1\n",
       "5074  Dishoom is di-licious. Go and see for yourself...          1\n",
       "4196  Just found this place by accident. What a find...          1\n",
       "563   I was taken here recently, specifically to be ...          1\n",
       "1438  I wasn't that impressed when I went to the Cov...          1\n",
       "968   I was in Soho with a friend planning to eat at...          1\n",
       "1077  After a long flight , and navigating out of th...          1\n",
       "3426  I don't usually eat japanese food in chinatown...         -1\n",
       "1548  I have to confirm that their roast duck Canton...         -1\n",
       "3204  I went here on a recent trip to London.  Absol...          1\n",
       "1026  this place will blow your mind in two ways.\\n1...          1\n",
       "5041  I've only been here for breakfast, which is th...          1\n",
       "1002  When this place first opened-up, I wasn't sure...          1\n",
       "1631  A run of the mill 3* from me for Ping Pong Sou...         -1\n",
       "3522  Tokyo Diner is such a relaxed spot. It is styl...          1\n",
       "3386  I really like this place. It's cheap and cheer...          1\n",
       "3491  Maybe it was an off night, but I did not have ...         -1\n",
       "5489  So amazing! Great food great service! This pla...          1\n",
       "3990  I stumbled in here when looking for somewhere ...          1\n",
       "...                                                 ...        ...\n",
       "1938  Was the first dim sum place I ever went to so ...         -1\n",
       "2252  Tried their house specialty chicken , the stew...          1\n",
       "452   Average. The ramen is decent, but far from imp...         -1\n",
       "2346  The food was fine, but if you are a tourist, c...         -1\n",
       "779   Cool spot. Great service and experience.  Dump...          1\n",
       "4171  My brother- and sister-in-law brought me to th...          1\n",
       "3217  Nothing short of amazing ate here twice while ...          1\n",
       "3085  Why I ended up at Roti Chai is the perfect exa...          1\n",
       "3125  Such a great place!! I ate at their street foo...          1\n",
       "3344  U can't find anything nicer tha Nobu! I have t...          1\n",
       "4035  I loved the New York version of this restauran...          1\n",
       "1503  Hearing reviews that this place was known for ...         -1\n",
       "3679  Tasty French food at a reasonable price. It wa...          1\n",
       "4970  The hype is real. There was an hour long wait ...          1\n",
       "4086  Nice ambiance, great service, but definitely o...          1\n",
       "4370  Firstly I would like to say it's the best rame...          1\n",
       "4598  I've always loved Indian food and I've been to...          1\n",
       "1660  Never in the history of Dim Sum have such smal...         -1\n",
       "4492  What a lunch feast to remember! Came here with...          1\n",
       "473   I was not impressed with the broth. I don't se...         -1\n",
       "2655  Let me say that I'm a big ramen fan, but I thi...         -1\n",
       "2517  I've never had ramen before but boy was I miss...          1\n",
       "4617  A fantastic and different place for breakfast ...          1\n",
       "2710  Authentic and Nice atmosphere. Friendly servic...          1\n",
       "904   This place is a treat if you love dim sum. I w...          1\n",
       "1807  Clos Maggiore in Covent Garden had excellent s...          1\n",
       "2962  This restaurant is not good for families . Whe...         -1\n",
       "4813  I had brunch here. Beware that brunch is until...          1\n",
       "742   Super modern setting, delicious food. The lych...          1\n",
       "135   I like the price the most.. AND the food is pr...          1\n",
       "\n",
       "[4021 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.05      1.00      0.09        44\n",
      "          1       1.00      0.78      0.88      3977\n",
      "\n",
      "avg / total       0.99      0.79      0.87      4021\n",
      "\n",
      "0.7851280775926387\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(pred,  train_lab))\n",
    "print (accuracy_score(pred, train_lab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "May need some preprocessing. See '4' as an informative feature. Makes sense? \n",
    "\n",
    "Now test on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred</th>\n",
       "      <th>-1</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actuals</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>4</td>\n",
       "      <td>385</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1335</td>\n",
       "      <td>1335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>4</td>\n",
       "      <td>1720</td>\n",
       "      <td>1724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred     -1     1   All\n",
       "actuals                \n",
       "-1        4   385   389\n",
       "1         0  1335  1335\n",
       "All       4  1720  1724"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predNB = clf.predict(test_vectors)\n",
    "pred = list(predNB)\n",
    "cm1=pd.crosstab( pd.Series(test_lab), pd.Series(pred), rownames= ['actuals'], colnames=['pred'],margins=True)\n",
    "cm1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.01      1.00      0.02         4\n",
      "          1       1.00      0.78      0.87      1720\n",
      "\n",
      "avg / total       1.00      0.78      0.87      1724\n",
      "\n",
      "0.7766821345707656\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(pred,  test_lab))\n",
    "print (accuracy_score(pred, test_lab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat Naive Bayes Classifier Using Combined Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                Terrible = True               -1 : 1      =     65.0 : 1.0\n",
      "                      Wo = True               -1 : 1      =     58.1 : 1.0\n",
      "                Horrible = True               -1 : 1      =     48.2 : 1.0\n",
      "               Brazilian = True               -1 : 1      =     45.5 : 1.0\n",
      "                     Meh = True               -1 : 1      =     41.1 : 1.0\n",
      "              flavorless = True               -1 : 1      =     39.0 : 1.0\n",
      "            unacceptable = True               -1 : 1      =     36.5 : 1.0\n",
      "                  rudely = True               -1 : 1      =     35.8 : 1.0\n",
      "                   WORST = True               -1 : 1      =     31.6 : 1.0\n",
      "              microwaved = True               -1 : 1      =     30.9 : 1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred</th>\n",
       "      <th>-1</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actuals</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>10295</td>\n",
       "      <td>1624</td>\n",
       "      <td>11919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1088</td>\n",
       "      <td>11343</td>\n",
       "      <td>12431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>11383</td>\n",
       "      <td>12967</td>\n",
       "      <td>24350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred        -1      1    All\n",
       "actuals                     \n",
       "-1       10295   1624  11919\n",
       "1         1088  11343  12431\n",
       "All      11383  12967  24350"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Naive Bayes Rule using nltk\n",
    "classifier_nb = NaiveBayesClassifier.train(train_all_featureset)\n",
    "#print(\"Accuracy :\" +str(accuracy(classifier_nb, test_featureset)))\n",
    "classifier_nb.show_most_informative_features(10)\n",
    "\n",
    "## Preparing the data first \n",
    "trainall_nolab = [t[0] for t in trainset_all]\n",
    "trainall_lab = [t[1] for t in trainset_all]\n",
    "\n",
    "# Create your tf-idf function\n",
    "vectorizer_all = TfidfVectorizer(max_df=0.7, min_df=3, use_idf=True) # modified this\n",
    "trainall_vectors = vectorizer_all.fit_transform(trainall_nolab)\n",
    "testall_vectors = vectorizer_all.transform(test_nolab)\n",
    "pk.dump(vectorizer_all, open(\"./models/vectorise.pk\",\"wb\"))\n",
    "\n",
    "## train Naive Bayes Rule using sklearn\n",
    "clf = MultinomialNB().fit(trainall_vectors, trainall_lab)\n",
    "pk.dump(clf, open(\"./models/classifier_naivebayes.pk\",\"wb\"))\n",
    "predNB = clf.predict(trainall_vectors)\n",
    "pred = list(predNB)\n",
    "cm1=pd.crosstab( pd.Series(trainall_lab), pd.Series(pred), rownames= ['actuals'], colnames=['pred'],margins=True)\n",
    "cm1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.86      0.90      0.88     11383\n",
      "          1       0.91      0.87      0.89     12967\n",
      "\n",
      "avg / total       0.89      0.89      0.89     24350\n",
      "\n",
      "0.8886242299794661\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(pred,  trainall_lab))\n",
    "print (accuracy_score(pred, trainall_lab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use full dataset-trained classifier on test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred</th>\n",
       "      <th>-1</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actuals</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>185</td>\n",
       "      <td>204</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65</td>\n",
       "      <td>1270</td>\n",
       "      <td>1335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>250</td>\n",
       "      <td>1474</td>\n",
       "      <td>1724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred      -1     1   All\n",
       "actuals                 \n",
       "-1       185   204   389\n",
       "1         65  1270  1335\n",
       "All      250  1474  1724"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predNB = clf.predict(testall_vectors)\n",
    "pred = list(predNB)\n",
    "cm1=pd.crosstab( pd.Series(test_lab), pd.Series(pred), rownames= ['actuals'], colnames=['pred'],margins=True)\n",
    "cm1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.48      0.74      0.58       250\n",
      "          1       0.95      0.86      0.90      1474\n",
      "\n",
      "avg / total       0.88      0.84      0.86      1724\n",
      "\n",
      "0.8439675174013921\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(pred,  test_lab))\n",
    "print (accuracy_score(pred, test_lab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred</th>\n",
       "      <th>-1</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actuals</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>864</td>\n",
       "      <td>44</td>\n",
       "      <td>908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>3099</td>\n",
       "      <td>3113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>878</td>\n",
       "      <td>3143</td>\n",
       "      <td>4021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred      -1     1   All\n",
       "actuals                 \n",
       "-1       864    44   908\n",
       "1         14  3099  3113\n",
       "All      878  3143  4021"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# SVM Classifier from sklearn\n",
    "def train_svm(X, y):\n",
    "    \"\"\"\n",
    "    Create and train the Support Vector Machine.\n",
    "    \"\"\"\n",
    "    svm = SVC(C=10000.0, gamma='auto', kernel='rbf')\n",
    "    svm.fit(X, y)\n",
    "    return svm\n",
    "\n",
    "classifier_svm = train_svm(train_vectors, train_lab)  # training the SVM model\n",
    "predSVM = classifier_svm.predict(train_vectors) \n",
    "cm1=pd.crosstab( pd.Series(train_lab), pd.Series(predSVM), rownames= ['actuals'], colnames=['pred'],margins=True)\n",
    "cm1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.95      0.98      0.97       878\n",
      "          1       1.00      0.99      0.99      3143\n",
      "\n",
      "avg / total       0.99      0.99      0.99      4021\n",
      "\n",
      "0.9855757274309873\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(predSVM,  train_lab))\n",
    "print (accuracy_score(predSVM, train_lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4021, 6223)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vectors.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1724, 6223)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predSVM = classifier_svm.predict(test_vectors) \n",
    "pred_svm = list(predSVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred</th>\n",
       "      <th>-1</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actuals</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>232</td>\n",
       "      <td>157</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91</td>\n",
       "      <td>1244</td>\n",
       "      <td>1335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>323</td>\n",
       "      <td>1401</td>\n",
       "      <td>1724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred      -1     1   All\n",
       "actuals                 \n",
       "-1       232   157   389\n",
       "1         91  1244  1335\n",
       "All      323  1401  1724"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm6=pd.crosstab( pd.Series(test_lab), pd.Series(pred_svm), rownames= ['actuals'], colnames=['pred'],margins=True)\n",
    "cm6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.60      0.72      0.65       323\n",
      "          1       0.93      0.89      0.91      1401\n",
      "\n",
      "avg / total       0.87      0.86      0.86      1724\n",
      "\n",
      "0.8561484918793504\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(pred_svm,  test_lab))\n",
    "print (accuracy_score(pred_svm, test_lab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat SVM Classifier using Combined Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_svm = train_svm(trainall_vectors, trainall_lab)  # training the SVM model\n",
    "pk.dump(classifier_svm, open(\"./models/classifier_svm.pk\",\"wb\"))\n",
    "predSVM = classifier_svm.predict(trainall_vectors) \n",
    "cm1=pd.crosstab( pd.Series(trainall_lab), pd.Series(predSVM), rownames= ['actuals'], colnames=['pred'],margins=True)\n",
    "cm1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (classification_report(predSVM,  trainall_lab))\n",
    "print (accuracy_score(predSVM, trainall_lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predSVM = classifier_svm.predict(testall_vectors) \n",
    "pred_svm = list(predSVM)\n",
    "cm6=pd.crosstab( pd.Series(test_lab), pd.Series(pred_svm), rownames= ['actuals'], colnames=['pred'],margins=True)\n",
    "cm6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (classification_report(pred_svm,  test_lab))\n",
    "print (accuracy_score(pred_svm, test_lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Ent Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (5 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.875\n",
      "             2          -0.27948        0.875\n",
      "             3          -0.23122        0.875\n",
      "             4          -0.19607        0.917\n",
      "         Final          -0.16931        0.958\n"
     ]
    }
   ],
   "source": [
    "classifier_me = MaxentClassifier.train(train_featureset, algorithm=\"IIS\", max_iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred      1  All\n",
      "actuals         \n",
      "-1        1    1\n",
      "1        10   10\n",
      "All      11   11\n"
     ]
    }
   ],
   "source": [
    "pred_me = []\n",
    "test_nolab_tok = [t[0] for t in test_featureset]  # need to transform to predict\n",
    "for t in test_nolab_tok:\n",
    "    pred_me.append(classifier_me.classify(t))\n",
    "\n",
    "cm5=pd.crosstab( pd.Series(test_lab), pd.Series(pred_me), rownames= ['actuals'], colnames=['pred'],margins=True)\n",
    "print (cm5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.00      0.00      0.00         0\n",
      "          1       1.00      0.91      0.95        11\n",
      "\n",
      "avg / total       1.00      0.91      0.95        11\n",
      "\n",
      "0.9090909090909091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierlim/anaconda/envs/tensorflow/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(pred_me,  test_lab))\n",
    "print (accuracy_score(pred_me, test_lab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat Max Ent Classifier with Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (5 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.459\n",
      "             2          -0.68658        0.472\n",
      "             3          -0.71457        0.469\n",
      "             4          -0.73350        0.468\n",
      "         Final          -0.74345        0.468\n",
      "pred      1  All\n",
      "actuals         \n",
      "-1        1    1\n",
      "1        10   10\n",
      "All      11   11\n"
     ]
    }
   ],
   "source": [
    "classifier_me = MaxentClassifier.train(train_all_featureset, algorithm=\"IIS\", max_iter=5)\n",
    "pred_me = []\n",
    "test_nolab_tok = [t[0] for t in test_featureset]  # need to transform to predict\n",
    "for t in test_nolab_tok:\n",
    "    pred_me.append(classifier_me.classify(t))\n",
    "\n",
    "cm5=pd.crosstab( pd.Series(test_lab), pd.Series(pred_me), rownames= ['actuals'], colnames=['pred'],margins=True)\n",
    "print (cm5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.00      0.00      0.00         0\n",
      "          1       1.00      0.91      0.95        11\n",
      "\n",
      "avg / total       1.00      0.91      0.95        11\n",
      "\n",
      "0.9090909090909091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierlim/anaconda/envs/tensorflow/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(pred_me,  test_lab))\n",
    "print (accuracy_score(pred_me, test_lab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use K Best Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO update this to run on full dataset \n",
    "\n",
    "ch21 = SelectKBest(chi2, k=500) # TODO modify k according to number of features you want \n",
    "# Transform your training and testing datasets accordingly\n",
    "train_Kbest = ch21.fit_transform(train_vectors, train_lab)\n",
    "test_Kbest = ch21.transform(test_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Best SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 255   80]\n",
      " [ 134 1255]]\n",
      "0.8758700696055685\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.66      0.76      0.70       335\n",
      "          1       0.94      0.90      0.92      1389\n",
      "\n",
      "avg / total       0.88      0.88      0.88      1724\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train your SVM with the k best selected features\n",
    "sv = train_svm(train_Kbest, train_lab)\n",
    "predSVM= sv.predict(test_Kbest)\n",
    "pred = list(predSVM)\n",
    "cm8 = confusion_matrix(pred, test_lab)\n",
    "print (cm8)\n",
    "print (accuracy_score(pred, test_lab))\n",
    "print (classification_report(pred,  test_lab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Best Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  12    0]\n",
      " [ 377 1335]]\n",
      "0.781322505800464\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.03      1.00      0.06        12\n",
      "          1       1.00      0.78      0.88      1712\n",
      "\n",
      "avg / total       0.99      0.78      0.87      1724\n",
      "\n",
      "['12', '17', '20', '99', 'about', 'absolutely', 'abysmal', 'acknowledged', 'acted', 'actual', 'adding', 'affordable', 'after', 'aimed', 'alot', 'alright', 'always', 'amazing', 'annoyed', 'anticipation', 'any', 'anything', 'apologetic', 'apology', 'appalling', 'appeal', 'argue', 'arguing', 'arrived', 'arrogant', 'arugula', 'ask', 'asked', 'asking', 'ass', 'at', 'atmosphere', 'attentive', 'attitude', 'average', 'awesome', 'awful', 'awkwardly', 'bad', 'badly', 'bags', 'barely', 'basic', 'bathroom', 'beautifully', 'below', 'berry', 'best', 'better', 'biggest', 'bill', 'biryani', 'black', 'bland', 'bleh', 'blowingly', 'boring', 'bother', 'brag', 'branches', 'breakfast', 'broth', 'buck', 'building', 'burnt', 'but', 'bye', 'canned', 'cantonese', 'celebs', 'cha', 'chai', 'chang', 'charge', 'charged', 'charging', 'cheaper', 'chicken', 'china', 'chinatown', 'chinatowns', 'chinese', 'choi', 'claimed', 'clarify', 'cleaner', 'clearly', 'cold', 'commercial', 'complained', 'cons', 'consideration', 'costs', 'couldn', 'count', 'cozy', 'croquettes', 'cuisine', 'customer', 'daal', 'dal', 'days', 'dead', 'decent', 'definitely', 'delayed', 'delicious', 'delish', 'depth', 'did', 'didn', 'die', 'diluted', 'dim', 'dimensional', 'dirty', 'disappoint', 'disappointed', 'disappointing', 'disappointment', 'disaster', 'discretionary', 'disgusting', 'dishing', 'dishoom', 'dismissive', 'disrespectful', 'distinctly', 'divine', 'do', 'dog', 'don', 'downhill', 'drenched', 'dry', 'dumpling', 'dying', 'early', 'ears', 'edible', 'eh', 'either', 'elsewhere', 'embarrassing', 'ends', 'enjoyed', 'error', 'essentially', 'ever', 'every', 'everything', 'excellent', 'excited', 'expect', 'expectations', 'expected', 'expecting', 'expensive', 'factory', 'fantastic', 'fatty', 'favorite', 'favourite', 'felt', 'fine', 'fired', 'flag', 'flash', 'flavorless', 'flies', 'forced', 'forever', 'forgetting', 'fortunately', 'frankly', 'french', 'friendly', 'frustrating', 'garlic', 'geared', 'gem', 'general', 'give', 'glad', 'gone', 'gow', 'grace', 'greasy', 'great', 'greens', 'guess', 'gymkhana', 'happening', 'har', 'harder', 'hardly', 'hassle', 'he', 'hear', 'heaven', 'help', 'helpful', 'her', 'high', 'highly', 'hill', 'hmm', 'hmmm', 'honest', 'hoping', 'horrible', 'house', 'however', 'ignored', 'ill', 'improved', 'inattentive', 'incompetent', 'incredible', 'indian', 'inedible', 'insipid', 'instead', 'insult', 'isn', 'izakaya', 'japan', 'japanese', 'jumping', 'just', 'justified', 'justify', 'kinda', 'kitchen', 'lack', 'lacked', 'lacking', 'lacks', 'lamb', 'learn', 'leave', 'left', 'letdown', 'like', 'limp', 'line', 'list', 'lively', 'london', 'look', 'looked', 'love', 'loved', 'lukewarm', 'ma', 'maki', 'man', 'manager', 'massala', 'masses', 'match', 'maybe', 'mcdonald', 'me', 'meals', 'mediocre', 'meh', 'mill', 'mistake', 'money', 'msg', 'much', 'museum', 'mushy', 'must', 'naan', 'nasty', 'neither', 'no', 'noise', 'nor', 'not', 'nothing', 'notice', 'off', 'offensive', 'ok', 'okay', 'okra', 'opentable', 'order', 'ordinary', 'other', 'our', 'outstanding', 'overall', 'overcooked', 'overpriced', 'overrated', 'paid', 'par', 'particularly', 'passable', 'pau', 'pay', 'paying', 'peanuts', 'people', 'perfect', 'perfection', 'perfectly', 'perhaps', 'phenomenal', 'piece', 'ping', 'poisoning', 'polish', 'pong', 'poor', 'poorly', 'positives', 'pounds', 'pour', 'pretty', 'price', 'problem', 'professional', 'profile', 'pros', 'pushing', 'questions', 'quite', 'racist', 'raised', 'ramen', 'rather', 'rating', 'received', 'recommend', 'recommended', 'refused', 'related', 'relatively', 'remind', 'remotely', 'remove', 'replaced', 'replied', 'reputation', 'reservations', 'reviews', 'riding', 'ripped', 'roti', 'rubbing', 'ruby', 'rude', 'rushing', 'sadly', 'said', 'salty', 'saving', 'saying', 'screaming', 'seats', 'see', 'seemed', 'seems', 'setting', 'shame', 'she', 'sheet', 'shocked', 'shoots', 'should', 'shouldn', 'shows', 'sink', 'sitting', 'skill', 'skills', 'skip', 'slice', 'slow', 'slowly', 'small', 'soggy', 'someplace', 'something', 'somewhat', 'sorry', 'soup', 'south', 'southbank', 'soy', 'special', 'speed', 'speedy', 'spending', 'spicy', 'spoiled', 'sprinkled', 'standard', 'starchy', 'stars', 'stay', 'steep', 'stranger', 'subpar', 'sum', 'superb', 'supposed', 'sushi', 'table', 'tables', 'taste', 'tasted', 'tasteless', 'temperature', 'terrible', 'tesco', 'that', 'them', 'there', 'they', 'thin', 'think', 'thou', 'though', 'tikka', 'time', 'today', 'tofu', 'toilet', 'told', 'tone', 'tonic', 'tonight', 'took', 'toronto', 'tough', 'tourist', 'trap', 'tray', 'turned', 'unacceptable', 'understand', 'underwhelmed', 'underwhelming', 'unfortunately', 'uninspired', 'uninterested', 'unless', 'unlikely', 'unnecessary', 'unpleasant', 'unprofessional', 'unremarkable', 'until', 'up', 'us', 'used', 'utter', 'visit', 'wait', 'waiter', 'waitstaff', 'walks', 'want', 'wanted', 'warrant', 'was', 'wasn', 'waste', 'water', 'watery', 'wave', 'way', 'wayyy', 'weak', 'weirdly', 'well', 'why', 'wing', 'wonderful', 'wonky', 'worse', 'worst', 'worth', 'wouldn', 'wouldnt', 'write', 'wtf', 'yum', 'yummy']\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB().fit(train_Kbest, train_lab)\n",
    "predNB = clf.predict(test_Kbest)\n",
    "pred = list(predNB)\n",
    "cm9 = confusion_matrix(pred, test_lab)\n",
    "print (cm9)\n",
    "print (accuracy_score(pred, test_lab))\n",
    "print (classification_report(pred,  test_lab))\n",
    "\n",
    "# View the selected features\n",
    "selected_features = list(np.array(vectorizer.get_feature_names())[ch21.get_support()])\n",
    "print (selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Best SVM with Combined Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO update this to run on full dataset \n",
    "\n",
    "ch21 = SelectKBest(chi2, k=50) # TODO modify k according to number of features you want \n",
    "# Transform your training and testing datasets accordingly\n",
    "train_Kbest = ch21.fit_transform(trainall_vectors, trainall_lab)\n",
    "test_Kbest = ch21.transform(testall_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 277  153]\n",
      " [ 112 1182]]\n",
      "0.8462877030162413\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.71      0.64      0.68       430\n",
      "          1       0.89      0.91      0.90      1294\n",
      "\n",
      "avg / total       0.84      0.85      0.84      1724\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train your SVM with the k best selected features\n",
    "sv = train_svm(train_Kbest, trainall_lab)\n",
    "predSVM= sv.predict(test_Kbest)\n",
    "pred = list(predSVM)\n",
    "cm8 = confusion_matrix(pred, test_lab)\n",
    "print (cm8)\n",
    "print (accuracy_score(pred, test_lab))\n",
    "print (classification_report(pred,  test_lab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Best Naive Bayes with Combined Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 221  104]\n",
      " [ 168 1231]]\n",
      "0.8422273781902552\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.57      0.68      0.62       325\n",
      "          1       0.92      0.88      0.90      1399\n",
      "\n",
      "avg / total       0.86      0.84      0.85      1724\n",
      "\n",
      "['always', 'amazing', 'asked', 'awesome', 'awful', 'bad', 'best', 'bland', 'burger', 'cold', 'definitely', 'delicious', 'didn', 'disgusting', 'dry', 'excellent', 'fantastic', 'favorite', 'friendly', 'great', 'he', 'her', 'highly', 'horrible', 'indian', 'london', 'love', 'loved', 'manager', 'mediocre', 'minutes', 'naan', 'no', 'not', 'nothing', 'ok', 'okay', 'overpriced', 'perfect', 'poor', 'rude', 'she', 'terrible', 'thai', 'told', 'waitress', 'was', 'wasn', 'wonderful', 'worst']\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB().fit(train_Kbest, trainall_lab)\n",
    "predNB = clf.predict(test_Kbest)\n",
    "pred = list(predNB)\n",
    "cm9 = confusion_matrix(pred, test_lab)\n",
    "print (cm9)\n",
    "print (accuracy_score(pred, test_lab))\n",
    "print (classification_report(pred,  test_lab))\n",
    "\n",
    "# View the selected features\n",
    "selected_features = list(np.array(vectorizer_all.get_feature_names())[ch21.get_support()])\n",
    "print (selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
