{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/pierlim/PycharmProjects/sent_mining_CA\n"
     ]
    }
   ],
   "source": [
    "from os import getcwd, chdir\n",
    "import re\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.metrics import ConfusionMatrix\n",
    "from nltk.classify import NaiveBayesClassifier, MaxentClassifier\n",
    "from nltk.classify import accuracy\n",
    "from nltk.tokenize import word_tokenize as wt\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Change your path here\n",
    "fpath = getcwd()\n",
    "print(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>take nice bite cheese swig wine trust divine m...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>london long stand indian restaurant hold title...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>best ramen london far place amaze want try ori...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>dishoom please come nyc love restaurant husban...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>wander soho drizzly cold summer day really aug...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                             review  sentiment\n",
       "0       3  take nice bite cheese swig wine trust divine m...         -1\n",
       "1       5  london long stand indian restaurant hold title...          1\n",
       "2       5  best ramen london far place amaze want try ori...          1\n",
       "3       5  dishoom please come nyc love restaurant husban...          1\n",
       "4       4  wander soho drizzly cold summer day really aug...          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/df_preprocessing.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Standard Dataset to combine with scrapped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Very disappointed in the customer service. We ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I really wasn't thrilled with our meal here. T...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STAY AWAY...\\n\\nWe've been 3 times over the pa...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The food is good and the portions are large.  ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I feel bad about giving this place such a meh ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  Very disappointed in the customer service. We ...  negative\n",
       "1  I really wasn't thrilled with our meal here. T...  negative\n",
       "2  STAY AWAY...\\n\\nWe've been 3 times over the pa...  negative\n",
       "3  The food is good and the portions are large.  ...  negative\n",
       "4  I feel bad about giving this place such a meh ...  negative"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffile1 = open(\"./data/train.csv\",\"r\", encoding = \"ISO-8859-1\")\n",
    "df_standard = pd.read_csv(ffile1, encoding = \"utf-8\")\n",
    "df_standard.drop(['restaurant_id', 'date', 'review_id', 'stars'], inplace=True, axis=1)\n",
    "df_standard.rename(columns={'text': 'review', 'Sentiment': 'sentiment'}, inplace=True)\n",
    "df_standard.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Very disappointed in the customer service. We ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I really wasn't thrilled with our meal here. T...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STAY AWAY...\\n\\nWe've been 3 times over the pa...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The food is good and the portions are large.  ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I feel bad about giving this place such a meh ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  Very disappointed in the customer service. We ...        -1\n",
       "1  I really wasn't thrilled with our meal here. T...        -1\n",
       "2  STAY AWAY...\\n\\nWe've been 3 times over the pa...        -1\n",
       "3  The food is good and the portions are large.  ...        -1\n",
       "4  I feel bad about giving this place such a meh ...        -1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = df_standard.sentiment == 'negative'\n",
    "column_name = 'sentiment'\n",
    "df_standard.loc[mask, column_name] = -1\n",
    "mask = df_standard.sentiment == 'positive'\n",
    "column_name = 'sentiment'\n",
    "df_standard.loc[mask, column_name] = 1\n",
    "\n",
    "df_standard.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data into Train and Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>take nice bite cheese swig wine trust divine m...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>london long stand indian restaurant hold title...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>best ramen london far place amaze want try ori...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dishoom please come nyc love restaurant husban...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wander soho drizzly cold summer day really aug...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  take nice bite cheese swig wine trust divine m...         -1\n",
       "1  london long stand indian restaurant hold title...          1\n",
       "2  best ramen london far place amaze want try ori...          1\n",
       "3  dishoom please come nyc love restaurant husban...          1\n",
       "4  wander soho drizzly cold summer day really aug...          1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train-Test Split + Stratify\n",
    "df.drop(['rating'], inplace=True, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df,stratify=df['sentiment'], test_size=0.3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train and df_standard are now the same format, we can concat and use it as a whole \n",
    "df_train_all = pd.concat([df_train, df_standard], axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dictionary format because apparently NLTK requires this\n",
    "train_pos = [[row[\"review\"], 1] for idx, row in df_train.iterrows() if row[\"sentiment\"]==1]\n",
    "train_neg = [[row[\"review\"], -1] for idx, row in df_train.iterrows() if row[\"sentiment\"]==-1]\n",
    "\n",
    "test_pos = [[row[\"review\"], 1] for idx, row in df_test.iterrows() if row[\"sentiment\"]==1]\n",
    "test_neg = [[row[\"review\"], -1] for idx, row in df_test.iterrows() if row[\"sentiment\"]==-1]\n",
    "\n",
    "def word_feats(words):\n",
    "    return dict([(word, True) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need this part for max ent portion\n",
    "testset = test_pos + test_neg\n",
    "test_nolab = [t[0] for t in testset]\n",
    "test_lab = [t[1] for t in testset]\n",
    "test_tokenized = [[wt(x), c] for x,c in testset]\n",
    "test_featureset = [(word_feats(d), c) for (d,c) in test_tokenized] \n",
    "test_nolab_tok = [t[0] for t in test_featureset]  # need to transform to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = train_pos + train_neg\n",
    "train_tokenized = [[wt(x), c] for x,c in trainset] # may need to introduce some pre-processing at this stage for better results\n",
    "\n",
    "def word_feats(words):\n",
    "    return dict([(word, True) for word in words])\n",
    "train_featureset = [(word_feats(d), c) for (d,c) in train_tokenized] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a combined training dataset of both scraped reviews and lecturer's standard set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_pos = [[row[\"review\"], 1] for idx, row in df_train_all.iterrows() if row[\"sentiment\"]==1]\n",
    "train_all_neg = [[row[\"review\"], -1] for idx, row in df_train_all.iterrows() if row[\"sentiment\"]==-1]\n",
    "trainset_all = train_all_pos + train_all_neg\n",
    "train_all_tokenized = [[wt(x), c] for x,c in trainset_all] # may need to introduce some pre-processing at this stage for better results\n",
    "train_all_featureset = [(word_feats(d), c) for (d,c) in train_all_tokenized] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                mediocre = True               -1 : 1      =     26.3 : 1.0\n",
      "                terrible = True               -1 : 1      =     25.0 : 1.0\n",
      "                   awful = True               -1 : 1      =     15.0 : 1.0\n",
      "           disappointing = True               -1 : 1      =     11.6 : 1.0\n",
      "                   waste = True               -1 : 1      =     11.4 : 1.0\n",
      "               tasteless = True               -1 : 1      =     11.0 : 1.0\n",
      "           underwhelming = True               -1 : 1      =     11.0 : 1.0\n",
      "                shouldnt = True               -1 : 1      =     10.3 : 1.0\n",
      "                   soggy = True               -1 : 1      =      9.7 : 1.0\n",
      "                  bother = True               -1 : 1      =      9.0 : 1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred</th>\n",
       "      <th>-1</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actuals</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>825</td>\n",
       "      <td>83</td>\n",
       "      <td>908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108</td>\n",
       "      <td>799</td>\n",
       "      <td>907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>933</td>\n",
       "      <td>882</td>\n",
       "      <td>1815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred      -1    1   All\n",
       "actuals                \n",
       "-1       825   83   908\n",
       "1        108  799   907\n",
       "All      933  882  1815"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Naive Bayes Rule using nltk\n",
    "classifier_nb = NaiveBayesClassifier.train(train_featureset)\n",
    "#print(\"Accuracy :\" +str(accuracy(classifier_nb, test_featureset)))\n",
    "classifier_nb.show_most_informative_features(10)\n",
    "\n",
    "## Preparing the data first \n",
    "train_nolab = [t[0] for t in trainset]\n",
    "train_lab = [t[1] for t in trainset]\n",
    "\n",
    "# Preparing test set in same format\n",
    "testset = test_pos + test_neg\n",
    "test_nolab = [t[0] for t in testset]\n",
    "test_lab = [t[1] for t in testset]\n",
    "\n",
    "# Create your tf-idf function\n",
    "vectorizer = TfidfVectorizer(max_df=0.7, min_df=3, use_idf=True) # modified this\n",
    "train_vectors = vectorizer.fit_transform(train_nolab)\n",
    "test_vectors = vectorizer.transform(test_nolab)\n",
    "\n",
    "## train Naive Bayes Rule using sklearn\n",
    "clf = MultinomialNB().fit(train_vectors, train_lab)\n",
    "\n",
    "predNB = clf.predict(train_vectors)\n",
    "pred = list(predNB)\n",
    "cm1=pd.crosstab( pd.Series(train_lab), pd.Series(pred), rownames= ['actuals'], colnames=['pred'],margins=True)\n",
    "cm1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "May need some preprocessing. See '4' as an informative feature. Makes sense? \n",
    "\n",
    "Now test on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred</th>\n",
       "      <th>-1</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actuals</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>307</td>\n",
       "      <td>82</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88</td>\n",
       "      <td>302</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>395</td>\n",
       "      <td>384</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred      -1    1  All\n",
       "actuals               \n",
       "-1       307   82  389\n",
       "1         88  302  390\n",
       "All      395  384  779"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predNB = clf.predict(test_vectors)\n",
    "pred = list(predNB)\n",
    "cm1=pd.crosstab( pd.Series(test_lab), pd.Series(pred), rownames= ['actuals'], colnames=['pred'],margins=True)\n",
    "cm1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.79      0.78      0.78       395\n",
      "          1       0.77      0.79      0.78       384\n",
      "\n",
      "avg / total       0.78      0.78      0.78       779\n",
      "\n",
      "0.7817715019255456\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(pred,  test_lab))\n",
    "print (accuracy_score(pred, test_lab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat Naive Bayes Classifier Using Combined Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                Terrible = True               -1 : 1      =     50.0 : 1.0\n",
      "              flavorless = True               -1 : 1      =     39.2 : 1.0\n",
      "                Horrible = True               -1 : 1      =     36.9 : 1.0\n",
      "               DELICIOUS = True                1 : -1     =     31.5 : 1.0\n",
      "                     Meh = True               -1 : 1      =     31.4 : 1.0\n",
      "            unacceptable = True               -1 : 1      =     30.0 : 1.0\n",
      "                  rudely = True               -1 : 1      =     29.5 : 1.0\n",
      "                HORRIBLE = True               -1 : 1      =     29.5 : 1.0\n",
      "                   WORST = True               -1 : 1      =     24.9 : 1.0\n",
      "                  filthy = True               -1 : 1      =     24.3 : 1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred</th>\n",
       "      <th>-1</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actuals</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>10804</td>\n",
       "      <td>1115</td>\n",
       "      <td>11919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1485</td>\n",
       "      <td>8740</td>\n",
       "      <td>10225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>12289</td>\n",
       "      <td>9855</td>\n",
       "      <td>22144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred        -1     1    All\n",
       "actuals                    \n",
       "-1       10804  1115  11919\n",
       "1         1485  8740  10225\n",
       "All      12289  9855  22144"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Naive Bayes Rule using nltk\n",
    "classifier_nb = NaiveBayesClassifier.train(train_all_featureset)\n",
    "#print(\"Accuracy :\" +str(accuracy(classifier_nb, test_featureset)))\n",
    "classifier_nb.show_most_informative_features(10)\n",
    "\n",
    "## Preparing the data first \n",
    "trainall_nolab = [t[0] for t in trainset_all]\n",
    "trainall_lab = [t[1] for t in trainset_all]\n",
    "\n",
    "# Create your tf-idf function\n",
    "vectorizer_all = TfidfVectorizer(max_df=0.7, min_df=3, use_idf=True) # modified this\n",
    "trainall_vectors = vectorizer_all.fit_transform(trainall_nolab)\n",
    "testall_vectors = vectorizer_all.transform(test_nolab)\n",
    "pk.dump(vectorizer_all, open(\"./models/vectorise.pk\",\"wb\"))\n",
    "\n",
    "## train Naive Bayes Rule using sklearn\n",
    "clf = MultinomialNB().fit(trainall_vectors, trainall_lab)\n",
    "pk.dump(clf, open(\"./models/classifier_naivebayes.pk\",\"wb\"))\n",
    "predNB = clf.predict(trainall_vectors)\n",
    "pred = list(predNB)\n",
    "cm1=pd.crosstab( pd.Series(trainall_lab), pd.Series(pred), rownames= ['actuals'], colnames=['pred'],margins=True)\n",
    "cm1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use full dataset-trained classifier on test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred</th>\n",
       "      <th>-1</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actuals</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>266</td>\n",
       "      <td>123</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41</td>\n",
       "      <td>349</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>307</td>\n",
       "      <td>472</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred      -1    1  All\n",
       "actuals               \n",
       "-1       266  123  389\n",
       "1         41  349  390\n",
       "All      307  472  779"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predNB = clf.predict(testall_vectors)\n",
    "pred = list(predNB)\n",
    "cm1=pd.crosstab( pd.Series(test_lab), pd.Series(pred), rownames= ['actuals'], colnames=['pred'],margins=True)\n",
    "cm1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.68      0.87      0.76       307\n",
      "          1       0.89      0.74      0.81       472\n",
      "\n",
      "avg / total       0.81      0.79      0.79       779\n",
      "\n",
      "0.7894736842105263\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(pred,  test_lab))\n",
    "print (accuracy_score(pred, test_lab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# SVM Classifier from sklearn\n",
    "def train_svm(X, y):\n",
    "    \"\"\"\n",
    "    Create and train the Support Vector Machine.\n",
    "    \"\"\"\n",
    "    svm = SVC(C=10000.0, gamma='auto', kernel='rbf')\n",
    "    svm.fit(X, y)\n",
    "    return svm\n",
    "\n",
    "classifier_svm = train_svm(train_vectors, train_lab)  # training the SVM model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1815, 3393)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vectors.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(779, 3393)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predSVM = classifier_svm.predict(test_vectors) \n",
    "pred_svm = list(predSVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred</th>\n",
       "      <th>-1</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actuals</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>297</td>\n",
       "      <td>92</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93</td>\n",
       "      <td>297</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>390</td>\n",
       "      <td>389</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred      -1    1  All\n",
       "actuals               \n",
       "-1       297   92  389\n",
       "1         93  297  390\n",
       "All      390  389  779"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm6=pd.crosstab( pd.Series(test_lab), pd.Series(pred_svm), rownames= ['actuals'], colnames=['pred'],margins=True)\n",
    "cm6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.76      0.76      0.76       390\n",
      "          1       0.76      0.76      0.76       389\n",
      "\n",
      "avg / total       0.76      0.76      0.76       779\n",
      "\n",
      "0.7625160462130937\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(pred_svm,  test_lab))\n",
    "print (accuracy_score(pred_svm, test_lab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat SVM Classifier using Combined Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred</th>\n",
       "      <th>-1</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actuals</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>312</td>\n",
       "      <td>77</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>339</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>363</td>\n",
       "      <td>416</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred      -1    1  All\n",
       "actuals               \n",
       "-1       312   77  389\n",
       "1         51  339  390\n",
       "All      363  416  779"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_svm = train_svm(trainall_vectors, trainall_lab)  # training the SVM model\n",
    "pk.dump(classifier_svm, open(\"./models/classifier_svm.pk\",\"wb\"))\n",
    "predSVM = classifier_svm.predict(testall_vectors) \n",
    "pred_svm = list(predSVM)\n",
    "cm6=pd.crosstab( pd.Series(test_lab), pd.Series(pred_svm), rownames= ['actuals'], colnames=['pred'],margins=True)\n",
    "cm6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.80      0.86      0.83       363\n",
      "          1       0.87      0.81      0.84       416\n",
      "\n",
      "avg / total       0.84      0.84      0.84       779\n",
      "\n",
      "0.8356867779204108\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(pred_svm,  test_lab))\n",
    "print (accuracy_score(pred_svm, test_lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Ent Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (5 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.875\n",
      "             2          -0.27948        0.875\n",
      "             3          -0.23122        0.875\n",
      "             4          -0.19607        0.917\n",
      "         Final          -0.16931        0.958\n"
     ]
    }
   ],
   "source": [
    "classifier_me = MaxentClassifier.train(train_featureset, algorithm=\"IIS\", max_iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred      1  All\n",
      "actuals         \n",
      "-1        1    1\n",
      "1        10   10\n",
      "All      11   11\n"
     ]
    }
   ],
   "source": [
    "pred_me = []\n",
    "test_nolab_tok = [t[0] for t in test_featureset]  # need to transform to predict\n",
    "for t in test_nolab_tok:\n",
    "    pred_me.append(classifier_me.classify(t))\n",
    "\n",
    "cm5=pd.crosstab( pd.Series(test_lab), pd.Series(pred_me), rownames= ['actuals'], colnames=['pred'],margins=True)\n",
    "print (cm5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.00      0.00      0.00         0\n",
      "          1       1.00      0.91      0.95        11\n",
      "\n",
      "avg / total       1.00      0.91      0.95        11\n",
      "\n",
      "0.9090909090909091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierlim/anaconda/envs/tensorflow/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(pred_me,  test_lab))\n",
    "print (accuracy_score(pred_me, test_lab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat Max Ent Classifier with Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (5 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.459\n",
      "             2          -0.68658        0.472\n",
      "             3          -0.71457        0.469\n",
      "             4          -0.73350        0.468\n",
      "         Final          -0.74345        0.468\n",
      "pred      1  All\n",
      "actuals         \n",
      "-1        1    1\n",
      "1        10   10\n",
      "All      11   11\n"
     ]
    }
   ],
   "source": [
    "classifier_me = MaxentClassifier.train(train_all_featureset, algorithm=\"IIS\", max_iter=5)\n",
    "pred_me = []\n",
    "test_nolab_tok = [t[0] for t in test_featureset]  # need to transform to predict\n",
    "for t in test_nolab_tok:\n",
    "    pred_me.append(classifier_me.classify(t))\n",
    "\n",
    "cm5=pd.crosstab( pd.Series(test_lab), pd.Series(pred_me), rownames= ['actuals'], colnames=['pred'],margins=True)\n",
    "print (cm5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.00      0.00      0.00         0\n",
      "          1       1.00      0.91      0.95        11\n",
      "\n",
      "avg / total       1.00      0.91      0.95        11\n",
      "\n",
      "0.9090909090909091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierlim/anaconda/envs/tensorflow/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(pred_me,  test_lab))\n",
    "print (accuracy_score(pred_me, test_lab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use K Best Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO update this to run on full dataset \n",
    "\n",
    "ch21 = SelectKBest(chi2, k=500) # TODO modify k according to number of features you want \n",
    "# Transform your training and testing datasets accordingly\n",
    "train_Kbest = ch21.fit_transform(train_vectors, train_lab)\n",
    "test_Kbest = ch21.transform(test_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Best SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 255   80]\n",
      " [ 134 1255]]\n",
      "0.8758700696055685\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.66      0.76      0.70       335\n",
      "          1       0.94      0.90      0.92      1389\n",
      "\n",
      "avg / total       0.88      0.88      0.88      1724\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train your SVM with the k best selected features\n",
    "sv = train_svm(train_Kbest, train_lab)\n",
    "predSVM= sv.predict(test_Kbest)\n",
    "pred = list(predSVM)\n",
    "cm8 = confusion_matrix(pred, test_lab)\n",
    "print (cm8)\n",
    "print (accuracy_score(pred, test_lab))\n",
    "print (classification_report(pred,  test_lab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Best Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  12    0]\n",
      " [ 377 1335]]\n",
      "0.781322505800464\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.03      1.00      0.06        12\n",
      "          1       1.00      0.78      0.88      1712\n",
      "\n",
      "avg / total       0.99      0.78      0.87      1724\n",
      "\n",
      "['12', '17', '20', '99', 'about', 'absolutely', 'abysmal', 'acknowledged', 'acted', 'actual', 'adding', 'affordable', 'after', 'aimed', 'alot', 'alright', 'always', 'amazing', 'annoyed', 'anticipation', 'any', 'anything', 'apologetic', 'apology', 'appalling', 'appeal', 'argue', 'arguing', 'arrived', 'arrogant', 'arugula', 'ask', 'asked', 'asking', 'ass', 'at', 'atmosphere', 'attentive', 'attitude', 'average', 'awesome', 'awful', 'awkwardly', 'bad', 'badly', 'bags', 'barely', 'basic', 'bathroom', 'beautifully', 'below', 'berry', 'best', 'better', 'biggest', 'bill', 'biryani', 'black', 'bland', 'bleh', 'blowingly', 'boring', 'bother', 'brag', 'branches', 'breakfast', 'broth', 'buck', 'building', 'burnt', 'but', 'bye', 'canned', 'cantonese', 'celebs', 'cha', 'chai', 'chang', 'charge', 'charged', 'charging', 'cheaper', 'chicken', 'china', 'chinatown', 'chinatowns', 'chinese', 'choi', 'claimed', 'clarify', 'cleaner', 'clearly', 'cold', 'commercial', 'complained', 'cons', 'consideration', 'costs', 'couldn', 'count', 'cozy', 'croquettes', 'cuisine', 'customer', 'daal', 'dal', 'days', 'dead', 'decent', 'definitely', 'delayed', 'delicious', 'delish', 'depth', 'did', 'didn', 'die', 'diluted', 'dim', 'dimensional', 'dirty', 'disappoint', 'disappointed', 'disappointing', 'disappointment', 'disaster', 'discretionary', 'disgusting', 'dishing', 'dishoom', 'dismissive', 'disrespectful', 'distinctly', 'divine', 'do', 'dog', 'don', 'downhill', 'drenched', 'dry', 'dumpling', 'dying', 'early', 'ears', 'edible', 'eh', 'either', 'elsewhere', 'embarrassing', 'ends', 'enjoyed', 'error', 'essentially', 'ever', 'every', 'everything', 'excellent', 'excited', 'expect', 'expectations', 'expected', 'expecting', 'expensive', 'factory', 'fantastic', 'fatty', 'favorite', 'favourite', 'felt', 'fine', 'fired', 'flag', 'flash', 'flavorless', 'flies', 'forced', 'forever', 'forgetting', 'fortunately', 'frankly', 'french', 'friendly', 'frustrating', 'garlic', 'geared', 'gem', 'general', 'give', 'glad', 'gone', 'gow', 'grace', 'greasy', 'great', 'greens', 'guess', 'gymkhana', 'happening', 'har', 'harder', 'hardly', 'hassle', 'he', 'hear', 'heaven', 'help', 'helpful', 'her', 'high', 'highly', 'hill', 'hmm', 'hmmm', 'honest', 'hoping', 'horrible', 'house', 'however', 'ignored', 'ill', 'improved', 'inattentive', 'incompetent', 'incredible', 'indian', 'inedible', 'insipid', 'instead', 'insult', 'isn', 'izakaya', 'japan', 'japanese', 'jumping', 'just', 'justified', 'justify', 'kinda', 'kitchen', 'lack', 'lacked', 'lacking', 'lacks', 'lamb', 'learn', 'leave', 'left', 'letdown', 'like', 'limp', 'line', 'list', 'lively', 'london', 'look', 'looked', 'love', 'loved', 'lukewarm', 'ma', 'maki', 'man', 'manager', 'massala', 'masses', 'match', 'maybe', 'mcdonald', 'me', 'meals', 'mediocre', 'meh', 'mill', 'mistake', 'money', 'msg', 'much', 'museum', 'mushy', 'must', 'naan', 'nasty', 'neither', 'no', 'noise', 'nor', 'not', 'nothing', 'notice', 'off', 'offensive', 'ok', 'okay', 'okra', 'opentable', 'order', 'ordinary', 'other', 'our', 'outstanding', 'overall', 'overcooked', 'overpriced', 'overrated', 'paid', 'par', 'particularly', 'passable', 'pau', 'pay', 'paying', 'peanuts', 'people', 'perfect', 'perfection', 'perfectly', 'perhaps', 'phenomenal', 'piece', 'ping', 'poisoning', 'polish', 'pong', 'poor', 'poorly', 'positives', 'pounds', 'pour', 'pretty', 'price', 'problem', 'professional', 'profile', 'pros', 'pushing', 'questions', 'quite', 'racist', 'raised', 'ramen', 'rather', 'rating', 'received', 'recommend', 'recommended', 'refused', 'related', 'relatively', 'remind', 'remotely', 'remove', 'replaced', 'replied', 'reputation', 'reservations', 'reviews', 'riding', 'ripped', 'roti', 'rubbing', 'ruby', 'rude', 'rushing', 'sadly', 'said', 'salty', 'saving', 'saying', 'screaming', 'seats', 'see', 'seemed', 'seems', 'setting', 'shame', 'she', 'sheet', 'shocked', 'shoots', 'should', 'shouldn', 'shows', 'sink', 'sitting', 'skill', 'skills', 'skip', 'slice', 'slow', 'slowly', 'small', 'soggy', 'someplace', 'something', 'somewhat', 'sorry', 'soup', 'south', 'southbank', 'soy', 'special', 'speed', 'speedy', 'spending', 'spicy', 'spoiled', 'sprinkled', 'standard', 'starchy', 'stars', 'stay', 'steep', 'stranger', 'subpar', 'sum', 'superb', 'supposed', 'sushi', 'table', 'tables', 'taste', 'tasted', 'tasteless', 'temperature', 'terrible', 'tesco', 'that', 'them', 'there', 'they', 'thin', 'think', 'thou', 'though', 'tikka', 'time', 'today', 'tofu', 'toilet', 'told', 'tone', 'tonic', 'tonight', 'took', 'toronto', 'tough', 'tourist', 'trap', 'tray', 'turned', 'unacceptable', 'understand', 'underwhelmed', 'underwhelming', 'unfortunately', 'uninspired', 'uninterested', 'unless', 'unlikely', 'unnecessary', 'unpleasant', 'unprofessional', 'unremarkable', 'until', 'up', 'us', 'used', 'utter', 'visit', 'wait', 'waiter', 'waitstaff', 'walks', 'want', 'wanted', 'warrant', 'was', 'wasn', 'waste', 'water', 'watery', 'wave', 'way', 'wayyy', 'weak', 'weirdly', 'well', 'why', 'wing', 'wonderful', 'wonky', 'worse', 'worst', 'worth', 'wouldn', 'wouldnt', 'write', 'wtf', 'yum', 'yummy']\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB().fit(train_Kbest, train_lab)\n",
    "predNB = clf.predict(test_Kbest)\n",
    "pred = list(predNB)\n",
    "cm9 = confusion_matrix(pred, test_lab)\n",
    "print (cm9)\n",
    "print (accuracy_score(pred, test_lab))\n",
    "print (classification_report(pred,  test_lab))\n",
    "\n",
    "# View the selected features\n",
    "selected_features = list(np.array(vectorizer.get_feature_names())[ch21.get_support()])\n",
    "print (selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Best SVM with Combined Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO update this to run on full dataset \n",
    "\n",
    "ch21 = SelectKBest(chi2, k=50) # TODO modify k according to number of features you want \n",
    "# Transform your training and testing datasets accordingly\n",
    "train_Kbest = ch21.fit_transform(trainall_vectors, trainall_lab)\n",
    "test_Kbest = ch21.transform(testall_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 277  153]\n",
      " [ 112 1182]]\n",
      "0.8462877030162413\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.71      0.64      0.68       430\n",
      "          1       0.89      0.91      0.90      1294\n",
      "\n",
      "avg / total       0.84      0.85      0.84      1724\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train your SVM with the k best selected features\n",
    "sv = train_svm(train_Kbest, trainall_lab)\n",
    "predSVM= sv.predict(test_Kbest)\n",
    "pred = list(predSVM)\n",
    "cm8 = confusion_matrix(pred, test_lab)\n",
    "print (cm8)\n",
    "print (accuracy_score(pred, test_lab))\n",
    "print (classification_report(pred,  test_lab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Best Naive Bayes with Combined Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 221  104]\n",
      " [ 168 1231]]\n",
      "0.8422273781902552\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.57      0.68      0.62       325\n",
      "          1       0.92      0.88      0.90      1399\n",
      "\n",
      "avg / total       0.86      0.84      0.85      1724\n",
      "\n",
      "['always', 'amazing', 'asked', 'awesome', 'awful', 'bad', 'best', 'bland', 'burger', 'cold', 'definitely', 'delicious', 'didn', 'disgusting', 'dry', 'excellent', 'fantastic', 'favorite', 'friendly', 'great', 'he', 'her', 'highly', 'horrible', 'indian', 'london', 'love', 'loved', 'manager', 'mediocre', 'minutes', 'naan', 'no', 'not', 'nothing', 'ok', 'okay', 'overpriced', 'perfect', 'poor', 'rude', 'she', 'terrible', 'thai', 'told', 'waitress', 'was', 'wasn', 'wonderful', 'worst']\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB().fit(train_Kbest, trainall_lab)\n",
    "predNB = clf.predict(test_Kbest)\n",
    "pred = list(predNB)\n",
    "cm9 = confusion_matrix(pred, test_lab)\n",
    "print (cm9)\n",
    "print (accuracy_score(pred, test_lab))\n",
    "print (classification_report(pred,  test_lab))\n",
    "\n",
    "# View the selected features\n",
    "selected_features = list(np.array(vectorizer_all.get_feature_names())[ch21.get_support()])\n",
    "print (selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
