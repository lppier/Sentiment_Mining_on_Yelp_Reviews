{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/pierlim/PycharmProjects/sent_mining_CA\n"
     ]
    }
   ],
   "source": [
    "from os import getcwd, chdir\n",
    "import re\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.metrics import ConfusionMatrix\n",
    "from nltk.classify import NaiveBayesClassifier, MaxentClassifier\n",
    "from nltk.classify import accuracy\n",
    "from nltk.tokenize import word_tokenize as wt\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Change your path here\n",
    "fpath = getcwd()\n",
    "print(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>In my younger days when lunch choices consiste...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>After going through yelp and tripadvisor, I wa...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Ordered Sichuan Prawns and Singapore Rice Nood...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Wong Kei is one of the many options you'll fin...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>One of the worst experience in a restaurant in...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                             review  sentiment\n",
       "0       5  In my younger days when lunch choices consiste...          1\n",
       "1       3  After going through yelp and tripadvisor, I wa...         -1\n",
       "2       5  Ordered Sichuan Prawns and Singapore Rice Nood...          1\n",
       "3       3  Wong Kei is one of the many options you'll fin...         -1\n",
       "4       1  One of the worst experience in a restaurant in...         -1"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/df_reviews_train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Standard Dataset to combine with scrapped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Very disappointed in the customer service. We ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I really wasn't thrilled with our meal here. T...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STAY AWAY...\\n\\nWe've been 3 times over the pa...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The food is good and the portions are large.  ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I feel bad about giving this place such a meh ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  Very disappointed in the customer service. We ...  negative\n",
       "1  I really wasn't thrilled with our meal here. T...  negative\n",
       "2  STAY AWAY...\\n\\nWe've been 3 times over the pa...  negative\n",
       "3  The food is good and the portions are large.  ...  negative\n",
       "4  I feel bad about giving this place such a meh ...  negative"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffile1 = open(\"./data/train.csv\",\"r\", encoding = \"ISO-8859-1\")\n",
    "df_standard = pd.read_csv(ffile1, encoding = \"utf-8\")\n",
    "df_standard.drop(['restaurant_id', 'date', 'review_id', 'stars'], inplace=True, axis=1)\n",
    "df_standard.rename(columns={'text': 'review', 'Sentiment': 'sentiment'}, inplace=True)\n",
    "df_standard.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Very disappointed in the customer service. We ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I really wasn't thrilled with our meal here. T...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STAY AWAY...\\n\\nWe've been 3 times over the pa...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The food is good and the portions are large.  ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I feel bad about giving this place such a meh ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  Very disappointed in the customer service. We ...        -1\n",
       "1  I really wasn't thrilled with our meal here. T...        -1\n",
       "2  STAY AWAY...\\n\\nWe've been 3 times over the pa...        -1\n",
       "3  The food is good and the portions are large.  ...        -1\n",
       "4  I feel bad about giving this place such a meh ...        -1"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = df_standard.sentiment == 'negative'\n",
    "column_name = 'sentiment'\n",
    "df_standard.loc[mask, column_name] = -1\n",
    "mask = df_standard.sentiment == 'positive'\n",
    "column_name = 'sentiment'\n",
    "df_standard.loc[mask, column_name] = 1\n",
    "\n",
    "df_standard.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data into Train and Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In my younger days when lunch choices consiste...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>After going through yelp and tripadvisor, I wa...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ordered Sichuan Prawns and Singapore Rice Nood...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wong Kei is one of the many options you'll fin...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>One of the worst experience in a restaurant in...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  In my younger days when lunch choices consiste...          1\n",
       "1  After going through yelp and tripadvisor, I wa...         -1\n",
       "2  Ordered Sichuan Prawns and Singapore Rice Nood...          1\n",
       "3  Wong Kei is one of the many options you'll fin...         -1\n",
       "4  One of the worst experience in a restaurant in...         -1"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train-Test Split + Stratify\n",
    "df.drop(['rating'], inplace=True, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df,stratify=df['sentiment'], test_size=0.3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train and df_standard are now the same format, we can concat and use it as a whole \n",
    "df_train_all = pd.concat([df_train, df_standard], axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dictionary format because apparently NLTK requires this\n",
    "train_pos = [[row[\"review\"], 1] for idx, row in df_train.iterrows() if row[\"sentiment\"]==1]\n",
    "train_neg = [[row[\"review\"], -1] for idx, row in df_train.iterrows() if row[\"sentiment\"]==-1]\n",
    "\n",
    "test_pos = [[row[\"review\"], 1] for idx, row in df_test.iterrows() if row[\"sentiment\"]==1]\n",
    "test_neg = [[row[\"review\"], -1] for idx, row in df_test.iterrows() if row[\"sentiment\"]==-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need this part for max ent portion\n",
    "testset = test_pos + test_neg\n",
    "test_nolab = [t[0] for t in testset]\n",
    "test_lab = [t[1] for t in testset]\n",
    "test_tokenized = [[wt(x), c] for x,c in testset]\n",
    "test_featureset = [(word_feats(d), c) for (d,c) in test_tokenized] \n",
    "test_nolab_tok = [t[0] for t in test_featureset]  # need to transform to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = train_pos + train_neg\n",
    "train_tokenized = [[wt(x), c] for x,c in trainset] # may need to introduce some pre-processing at this stage for better results\n",
    "\n",
    "def word_feats(words):\n",
    "    return dict([(word, True) for word in words])\n",
    "train_featureset = [(word_feats(d), c) for (d,c) in train_tokenized] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a combined training dataset of both scraped reviews and lecturer's standard set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_pos = [[row[\"review\"], 1] for idx, row in df_train_all.iterrows() if row[\"sentiment\"]==1]\n",
    "train_all_neg = [[row[\"review\"], -1] for idx, row in df_train_all.iterrows() if row[\"sentiment\"]==-1]\n",
    "trainset_all = train_all_pos + train_all_neg\n",
    "train_all_tokenized = [[wt(x), c] for x,c in trainset_all] # may need to introduce some pre-processing at this stage for better results\n",
    "train_all_featureset = [(word_feats(d), c) for (d,c) in train_all_tokenized] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                inedible = True               -1 : 1      =     24.0 : 1.0\n",
      "               overrated = True               -1 : 1      =     19.9 : 1.0\n",
      "                 Average = True               -1 : 1      =     19.4 : 1.0\n",
      "              complained = True               -1 : 1      =     19.4 : 1.0\n",
      "              flavorless = True               -1 : 1      =     19.4 : 1.0\n",
      "                  subpar = True               -1 : 1      =     19.4 : 1.0\n",
      "                 refused = True               -1 : 1      =     19.4 : 1.0\n",
      "                Horrible = True               -1 : 1      =     17.1 : 1.0\n",
      "                     ok. = True               -1 : 1      =     15.8 : 1.0\n",
      "                   worst = True               -1 : 1      =     14.8 : 1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred</th>\n",
       "      <th>-1</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actuals</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>41</td>\n",
       "      <td>867</td>\n",
       "      <td>908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3113</td>\n",
       "      <td>3113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>41</td>\n",
       "      <td>3980</td>\n",
       "      <td>4021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred     -1     1   All\n",
       "actuals                \n",
       "-1       41   867   908\n",
       "1         0  3113  3113\n",
       "All      41  3980  4021"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Naive Bayes Rule using nltk\n",
    "classifier_nb = NaiveBayesClassifier.train(train_featureset)\n",
    "#print(\"Accuracy :\" +str(accuracy(classifier_nb, test_featureset)))\n",
    "classifier_nb.show_most_informative_features(10)\n",
    "\n",
    "## Preparing the data first \n",
    "train_nolab = [t[0] for t in trainset]\n",
    "train_lab = [t[1] for t in trainset]\n",
    "\n",
    "# Preparing test set in same format\n",
    "testset = test_pos + test_neg\n",
    "test_nolab = [t[0] for t in testset]\n",
    "test_lab = [t[1] for t in testset]\n",
    "\n",
    "# Create your tf-idf function\n",
    "vectorizer = TfidfVectorizer(max_df=0.7, min_df=3, use_idf=True) # modified this\n",
    "train_vectors = vectorizer.fit_transform(train_nolab)\n",
    "test_vectors = vectorizer.transform(test_nolab)\n",
    "\n",
    "## train Naive Bayes Rule using sklearn\n",
    "clf = MultinomialNB().fit(train_vectors, train_lab)\n",
    "\n",
    "predNB = clf.predict(train_vectors)\n",
    "pred = list(predNB)\n",
    "cm1=pd.crosstab( pd.Series(train_lab), pd.Series(pred), rownames= ['actuals'], colnames=['pred'],margins=True)\n",
    "cm1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "May need some preprocessing. See '4' as an informative feature. Makes sense? \n",
    "\n",
    "Now test on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred</th>\n",
       "      <th>-1</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actuals</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>4</td>\n",
       "      <td>385</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1335</td>\n",
       "      <td>1335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>4</td>\n",
       "      <td>1720</td>\n",
       "      <td>1724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred     -1     1   All\n",
       "actuals                \n",
       "-1        4   385   389\n",
       "1         0  1335  1335\n",
       "All       4  1720  1724"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predNB = clf.predict(test_vectors)\n",
    "pred = list(predNB)\n",
    "cm1=pd.crosstab( pd.Series(test_lab), pd.Series(pred), rownames= ['actuals'], colnames=['pred'],margins=True)\n",
    "cm1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.01      1.00      0.02         4\n",
      "          1       1.00      0.78      0.87      1720\n",
      "\n",
      "avg / total       1.00      0.78      0.87      1724\n",
      "\n",
      "0.7766821345707656\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(pred,  test_lab))\n",
    "print (accuracy_score(pred, test_lab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat Naive Bayes Classifier Using Combined Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                Terrible = True               -1 : 1      =     64.3 : 1.0\n",
      "                      Wo = True               -1 : 1      =     56.7 : 1.0\n",
      "               Brazilian = True               -1 : 1      =     45.5 : 1.0\n",
      "                     Meh = True               -1 : 1      =     39.8 : 1.0\n",
      "              flavorless = True               -1 : 1      =     39.2 : 1.0\n",
      "            unacceptable = True               -1 : 1      =     37.2 : 1.0\n",
      "                HORRIBLE = True               -1 : 1      =     35.8 : 1.0\n",
      "                  rudely = True               -1 : 1      =     35.1 : 1.0\n",
      "                Horrible = True               -1 : 1      =     34.1 : 1.0\n",
      "                   WORST = True               -1 : 1      =     30.9 : 1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred</th>\n",
       "      <th>-1</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actuals</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>10294</td>\n",
       "      <td>1625</td>\n",
       "      <td>11919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1116</td>\n",
       "      <td>11315</td>\n",
       "      <td>12431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>11410</td>\n",
       "      <td>12940</td>\n",
       "      <td>24350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred        -1      1    All\n",
       "actuals                     \n",
       "-1       10294   1625  11919\n",
       "1         1116  11315  12431\n",
       "All      11410  12940  24350"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Naive Bayes Rule using nltk\n",
    "classifier_nb = NaiveBayesClassifier.train(train_all_featureset)\n",
    "#print(\"Accuracy :\" +str(accuracy(classifier_nb, test_featureset)))\n",
    "classifier_nb.show_most_informative_features(10)\n",
    "\n",
    "## Preparing the data first \n",
    "trainall_nolab = [t[0] for t in trainset_all]\n",
    "trainall_lab = [t[1] for t in trainset_all]\n",
    "\n",
    "# Create your tf-idf function\n",
    "vectorizer_all = TfidfVectorizer(max_df=0.7, min_df=3, use_idf=True) # modified this\n",
    "trainall_vectors = vectorizer_all.fit_transform(trainall_nolab)\n",
    "testall_vectors = vectorizer_all.transform(test_nolab)\n",
    "pk.dump(vectorizer_all, open(\"./models/vectorise.pk\",\"wb\"))\n",
    "\n",
    "## train Naive Bayes Rule using sklearn\n",
    "clf = MultinomialNB().fit(trainall_vectors, trainall_lab)\n",
    "pk.dump(clf, open(\"./models/classifier_naivebayes.pk\",\"wb\"))\n",
    "predNB = clf.predict(trainall_vectors)\n",
    "pred = list(predNB)\n",
    "cm1=pd.crosstab( pd.Series(trainall_lab), pd.Series(pred), rownames= ['actuals'], colnames=['pred'],margins=True)\n",
    "cm1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use full dataset-trained classifier on test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred</th>\n",
       "      <th>-1</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actuals</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>207</td>\n",
       "      <td>182</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1282</td>\n",
       "      <td>1335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>260</td>\n",
       "      <td>1464</td>\n",
       "      <td>1724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred      -1     1   All\n",
       "actuals                 \n",
       "-1       207   182   389\n",
       "1         53  1282  1335\n",
       "All      260  1464  1724"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predNB = clf.predict(testall_vectors)\n",
    "pred = list(predNB)\n",
    "cm1=pd.crosstab( pd.Series(test_lab), pd.Series(pred), rownames= ['actuals'], colnames=['pred'],margins=True)\n",
    "cm1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.53      0.80      0.64       260\n",
      "          1       0.96      0.88      0.92      1464\n",
      "\n",
      "avg / total       0.90      0.86      0.87      1724\n",
      "\n",
      "0.8636890951276102\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(pred,  test_lab))\n",
    "print (accuracy_score(pred, test_lab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# SVM Classifier from sklearn\n",
    "def train_svm(X, y):\n",
    "    \"\"\"\n",
    "    Create and train the Support Vector Machine.\n",
    "    \"\"\"\n",
    "    svm = SVC(C=10000.0, gamma='auto', kernel='rbf')\n",
    "    svm.fit(X, y)\n",
    "    return svm\n",
    "\n",
    "classifier_svm = train_svm(train_vectors, train_lab)  # training the SVM model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4021, 6147)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vectors.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1724, 6147)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "predSVM = classifier_svm.predict(test_vectors) \n",
    "pred_svm = list(predSVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred</th>\n",
       "      <th>-1</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actuals</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>253</td>\n",
       "      <td>136</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>1235</td>\n",
       "      <td>1335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>353</td>\n",
       "      <td>1371</td>\n",
       "      <td>1724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred      -1     1   All\n",
       "actuals                 \n",
       "-1       253   136   389\n",
       "1        100  1235  1335\n",
       "All      353  1371  1724"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm6=pd.crosstab( pd.Series(test_lab), pd.Series(pred_svm), rownames= ['actuals'], colnames=['pred'],margins=True)\n",
    "cm6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.65      0.72      0.68       353\n",
      "          1       0.93      0.90      0.91      1371\n",
      "\n",
      "avg / total       0.87      0.86      0.87      1724\n",
      "\n",
      "0.8631090487238979\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(pred_svm,  test_lab))\n",
    "print (accuracy_score(pred_svm, test_lab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat SVM Classifier using Combined Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred</th>\n",
       "      <th>-1</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actuals</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>279</td>\n",
       "      <td>110</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83</td>\n",
       "      <td>1252</td>\n",
       "      <td>1335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>362</td>\n",
       "      <td>1362</td>\n",
       "      <td>1724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred      -1     1   All\n",
       "actuals                 \n",
       "-1       279   110   389\n",
       "1         83  1252  1335\n",
       "All      362  1362  1724"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_svm = train_svm(trainall_vectors, trainall_lab)  # training the SVM model\n",
    "pk.dump(classifier_svm, open(\"./models/classifier_svm.pk\",\"wb\"))\n",
    "predSVM = classifier_svm.predict(testall_vectors) \n",
    "pred_svm = list(predSVM)\n",
    "cm6=pd.crosstab( pd.Series(test_lab), pd.Series(pred_svm), rownames= ['actuals'], colnames=['pred'],margins=True)\n",
    "cm6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.72      0.77      0.74       362\n",
      "          1       0.94      0.92      0.93      1362\n",
      "\n",
      "avg / total       0.89      0.89      0.89      1724\n",
      "\n",
      "0.8880510440835266\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(pred_svm,  test_lab))\n",
    "print (accuracy_score(pred_svm, test_lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Ent Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (5 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.875\n",
      "             2          -0.27948        0.875\n",
      "             3          -0.23122        0.875\n",
      "             4          -0.19607        0.917\n",
      "         Final          -0.16931        0.958\n"
     ]
    }
   ],
   "source": [
    "classifier_me = MaxentClassifier.train(train_featureset, algorithm=\"IIS\", max_iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred      1  All\n",
      "actuals         \n",
      "-1        1    1\n",
      "1        10   10\n",
      "All      11   11\n"
     ]
    }
   ],
   "source": [
    "pred_me = []\n",
    "test_nolab_tok = [t[0] for t in test_featureset]  # need to transform to predict\n",
    "for t in test_nolab_tok:\n",
    "    pred_me.append(classifier_me.classify(t))\n",
    "\n",
    "cm5=pd.crosstab( pd.Series(test_lab), pd.Series(pred_me), rownames= ['actuals'], colnames=['pred'],margins=True)\n",
    "print (cm5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.00      0.00      0.00         0\n",
      "          1       1.00      0.91      0.95        11\n",
      "\n",
      "avg / total       1.00      0.91      0.95        11\n",
      "\n",
      "0.9090909090909091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierlim/anaconda/envs/tensorflow/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(pred_me,  test_lab))\n",
    "print (accuracy_score(pred_me, test_lab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat Max Ent Classifier with Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (5 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.459\n",
      "             2          -0.68658        0.472\n",
      "             3          -0.71457        0.469\n",
      "             4          -0.73350        0.468\n",
      "         Final          -0.74345        0.468\n",
      "pred      1  All\n",
      "actuals         \n",
      "-1        1    1\n",
      "1        10   10\n",
      "All      11   11\n"
     ]
    }
   ],
   "source": [
    "classifier_me = MaxentClassifier.train(train_all_featureset, algorithm=\"IIS\", max_iter=5)\n",
    "pred_me = []\n",
    "test_nolab_tok = [t[0] for t in test_featureset]  # need to transform to predict\n",
    "for t in test_nolab_tok:\n",
    "    pred_me.append(classifier_me.classify(t))\n",
    "\n",
    "cm5=pd.crosstab( pd.Series(test_lab), pd.Series(pred_me), rownames= ['actuals'], colnames=['pred'],margins=True)\n",
    "print (cm5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.00      0.00      0.00         0\n",
      "          1       1.00      0.91      0.95        11\n",
      "\n",
      "avg / total       1.00      0.91      0.95        11\n",
      "\n",
      "0.9090909090909091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierlim/anaconda/envs/tensorflow/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(pred_me,  test_lab))\n",
    "print (accuracy_score(pred_me, test_lab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use K Best Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO update this to run on full dataset \n",
    "\n",
    "ch21 = SelectKBest(chi2, k=500) # TODO modify k according to number of features you want \n",
    "# Transform your training and testing datasets accordingly\n",
    "train_Kbest = ch21.fit_transform(train_vectors, train_lab)\n",
    "test_Kbest = ch21.transform(test_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Best SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 255   80]\n",
      " [ 134 1255]]\n",
      "0.8758700696055685\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.66      0.76      0.70       335\n",
      "          1       0.94      0.90      0.92      1389\n",
      "\n",
      "avg / total       0.88      0.88      0.88      1724\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train your SVM with the k best selected features\n",
    "sv = train_svm(train_Kbest, train_lab)\n",
    "predSVM= sv.predict(test_Kbest)\n",
    "pred = list(predSVM)\n",
    "cm8 = confusion_matrix(pred, test_lab)\n",
    "print (cm8)\n",
    "print (accuracy_score(pred, test_lab))\n",
    "print (classification_report(pred,  test_lab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Best Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  12    0]\n",
      " [ 377 1335]]\n",
      "0.781322505800464\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.03      1.00      0.06        12\n",
      "          1       1.00      0.78      0.88      1712\n",
      "\n",
      "avg / total       0.99      0.78      0.87      1724\n",
      "\n",
      "['12', '17', '20', '99', 'about', 'absolutely', 'abysmal', 'acknowledged', 'acted', 'actual', 'adding', 'affordable', 'after', 'aimed', 'alot', 'alright', 'always', 'amazing', 'annoyed', 'anticipation', 'any', 'anything', 'apologetic', 'apology', 'appalling', 'appeal', 'argue', 'arguing', 'arrived', 'arrogant', 'arugula', 'ask', 'asked', 'asking', 'ass', 'at', 'atmosphere', 'attentive', 'attitude', 'average', 'awesome', 'awful', 'awkwardly', 'bad', 'badly', 'bags', 'barely', 'basic', 'bathroom', 'beautifully', 'below', 'berry', 'best', 'better', 'biggest', 'bill', 'biryani', 'black', 'bland', 'bleh', 'blowingly', 'boring', 'bother', 'brag', 'branches', 'breakfast', 'broth', 'buck', 'building', 'burnt', 'but', 'bye', 'canned', 'cantonese', 'celebs', 'cha', 'chai', 'chang', 'charge', 'charged', 'charging', 'cheaper', 'chicken', 'china', 'chinatown', 'chinatowns', 'chinese', 'choi', 'claimed', 'clarify', 'cleaner', 'clearly', 'cold', 'commercial', 'complained', 'cons', 'consideration', 'costs', 'couldn', 'count', 'cozy', 'croquettes', 'cuisine', 'customer', 'daal', 'dal', 'days', 'dead', 'decent', 'definitely', 'delayed', 'delicious', 'delish', 'depth', 'did', 'didn', 'die', 'diluted', 'dim', 'dimensional', 'dirty', 'disappoint', 'disappointed', 'disappointing', 'disappointment', 'disaster', 'discretionary', 'disgusting', 'dishing', 'dishoom', 'dismissive', 'disrespectful', 'distinctly', 'divine', 'do', 'dog', 'don', 'downhill', 'drenched', 'dry', 'dumpling', 'dying', 'early', 'ears', 'edible', 'eh', 'either', 'elsewhere', 'embarrassing', 'ends', 'enjoyed', 'error', 'essentially', 'ever', 'every', 'everything', 'excellent', 'excited', 'expect', 'expectations', 'expected', 'expecting', 'expensive', 'factory', 'fantastic', 'fatty', 'favorite', 'favourite', 'felt', 'fine', 'fired', 'flag', 'flash', 'flavorless', 'flies', 'forced', 'forever', 'forgetting', 'fortunately', 'frankly', 'french', 'friendly', 'frustrating', 'garlic', 'geared', 'gem', 'general', 'give', 'glad', 'gone', 'gow', 'grace', 'greasy', 'great', 'greens', 'guess', 'gymkhana', 'happening', 'har', 'harder', 'hardly', 'hassle', 'he', 'hear', 'heaven', 'help', 'helpful', 'her', 'high', 'highly', 'hill', 'hmm', 'hmmm', 'honest', 'hoping', 'horrible', 'house', 'however', 'ignored', 'ill', 'improved', 'inattentive', 'incompetent', 'incredible', 'indian', 'inedible', 'insipid', 'instead', 'insult', 'isn', 'izakaya', 'japan', 'japanese', 'jumping', 'just', 'justified', 'justify', 'kinda', 'kitchen', 'lack', 'lacked', 'lacking', 'lacks', 'lamb', 'learn', 'leave', 'left', 'letdown', 'like', 'limp', 'line', 'list', 'lively', 'london', 'look', 'looked', 'love', 'loved', 'lukewarm', 'ma', 'maki', 'man', 'manager', 'massala', 'masses', 'match', 'maybe', 'mcdonald', 'me', 'meals', 'mediocre', 'meh', 'mill', 'mistake', 'money', 'msg', 'much', 'museum', 'mushy', 'must', 'naan', 'nasty', 'neither', 'no', 'noise', 'nor', 'not', 'nothing', 'notice', 'off', 'offensive', 'ok', 'okay', 'okra', 'opentable', 'order', 'ordinary', 'other', 'our', 'outstanding', 'overall', 'overcooked', 'overpriced', 'overrated', 'paid', 'par', 'particularly', 'passable', 'pau', 'pay', 'paying', 'peanuts', 'people', 'perfect', 'perfection', 'perfectly', 'perhaps', 'phenomenal', 'piece', 'ping', 'poisoning', 'polish', 'pong', 'poor', 'poorly', 'positives', 'pounds', 'pour', 'pretty', 'price', 'problem', 'professional', 'profile', 'pros', 'pushing', 'questions', 'quite', 'racist', 'raised', 'ramen', 'rather', 'rating', 'received', 'recommend', 'recommended', 'refused', 'related', 'relatively', 'remind', 'remotely', 'remove', 'replaced', 'replied', 'reputation', 'reservations', 'reviews', 'riding', 'ripped', 'roti', 'rubbing', 'ruby', 'rude', 'rushing', 'sadly', 'said', 'salty', 'saving', 'saying', 'screaming', 'seats', 'see', 'seemed', 'seems', 'setting', 'shame', 'she', 'sheet', 'shocked', 'shoots', 'should', 'shouldn', 'shows', 'sink', 'sitting', 'skill', 'skills', 'skip', 'slice', 'slow', 'slowly', 'small', 'soggy', 'someplace', 'something', 'somewhat', 'sorry', 'soup', 'south', 'southbank', 'soy', 'special', 'speed', 'speedy', 'spending', 'spicy', 'spoiled', 'sprinkled', 'standard', 'starchy', 'stars', 'stay', 'steep', 'stranger', 'subpar', 'sum', 'superb', 'supposed', 'sushi', 'table', 'tables', 'taste', 'tasted', 'tasteless', 'temperature', 'terrible', 'tesco', 'that', 'them', 'there', 'they', 'thin', 'think', 'thou', 'though', 'tikka', 'time', 'today', 'tofu', 'toilet', 'told', 'tone', 'tonic', 'tonight', 'took', 'toronto', 'tough', 'tourist', 'trap', 'tray', 'turned', 'unacceptable', 'understand', 'underwhelmed', 'underwhelming', 'unfortunately', 'uninspired', 'uninterested', 'unless', 'unlikely', 'unnecessary', 'unpleasant', 'unprofessional', 'unremarkable', 'until', 'up', 'us', 'used', 'utter', 'visit', 'wait', 'waiter', 'waitstaff', 'walks', 'want', 'wanted', 'warrant', 'was', 'wasn', 'waste', 'water', 'watery', 'wave', 'way', 'wayyy', 'weak', 'weirdly', 'well', 'why', 'wing', 'wonderful', 'wonky', 'worse', 'worst', 'worth', 'wouldn', 'wouldnt', 'write', 'wtf', 'yum', 'yummy']\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB().fit(train_Kbest, train_lab)\n",
    "predNB = clf.predict(test_Kbest)\n",
    "pred = list(predNB)\n",
    "cm9 = confusion_matrix(pred, test_lab)\n",
    "print (cm9)\n",
    "print (accuracy_score(pred, test_lab))\n",
    "print (classification_report(pred,  test_lab))\n",
    "\n",
    "# View the selected features\n",
    "selected_features = list(np.array(vectorizer.get_feature_names())[ch21.get_support()])\n",
    "print (selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Best SVM with Combined Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO update this to run on full dataset \n",
    "\n",
    "ch21 = SelectKBest(chi2, k=50) # TODO modify k according to number of features you want \n",
    "# Transform your training and testing datasets accordingly\n",
    "train_Kbest = ch21.fit_transform(trainall_vectors, trainall_lab)\n",
    "test_Kbest = ch21.transform(testall_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 277  153]\n",
      " [ 112 1182]]\n",
      "0.8462877030162413\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.71      0.64      0.68       430\n",
      "          1       0.89      0.91      0.90      1294\n",
      "\n",
      "avg / total       0.84      0.85      0.84      1724\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train your SVM with the k best selected features\n",
    "sv = train_svm(train_Kbest, trainall_lab)\n",
    "predSVM= sv.predict(test_Kbest)\n",
    "pred = list(predSVM)\n",
    "cm8 = confusion_matrix(pred, test_lab)\n",
    "print (cm8)\n",
    "print (accuracy_score(pred, test_lab))\n",
    "print (classification_report(pred,  test_lab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Best Naive Bayes with Combined Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 221  104]\n",
      " [ 168 1231]]\n",
      "0.8422273781902552\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.57      0.68      0.62       325\n",
      "          1       0.92      0.88      0.90      1399\n",
      "\n",
      "avg / total       0.86      0.84      0.85      1724\n",
      "\n",
      "['always', 'amazing', 'asked', 'awesome', 'awful', 'bad', 'best', 'bland', 'burger', 'cold', 'definitely', 'delicious', 'didn', 'disgusting', 'dry', 'excellent', 'fantastic', 'favorite', 'friendly', 'great', 'he', 'her', 'highly', 'horrible', 'indian', 'london', 'love', 'loved', 'manager', 'mediocre', 'minutes', 'naan', 'no', 'not', 'nothing', 'ok', 'okay', 'overpriced', 'perfect', 'poor', 'rude', 'she', 'terrible', 'thai', 'told', 'waitress', 'was', 'wasn', 'wonderful', 'worst']\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB().fit(train_Kbest, trainall_lab)\n",
    "predNB = clf.predict(test_Kbest)\n",
    "pred = list(predNB)\n",
    "cm9 = confusion_matrix(pred, test_lab)\n",
    "print (cm9)\n",
    "print (accuracy_score(pred, test_lab))\n",
    "print (classification_report(pred,  test_lab))\n",
    "\n",
    "# View the selected features\n",
    "selected_features = list(np.array(vectorizer_all.get_feature_names())[ch21.get_support()])\n",
    "print (selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
