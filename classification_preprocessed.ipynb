{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification on Pre-processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/pierlim/PycharmProjects/sent_mining_CA\n",
      "(2594, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>take nice bite cheese swig wine trust divine m...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>london long stand indian restaurant hold title...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>best ramen london far place amaze want try ori...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>dishoom please come nyc love restaurant husban...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>wander soho drizzly cold summer day really aug...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                             review  sentiment\n",
       "0       3  take nice bite cheese swig wine trust divine m...         -1\n",
       "1       5  london long stand indian restaurant hold title...          1\n",
       "2       5  best ramen london far place amaze want try ori...          1\n",
       "3       5  dishoom please come nyc love restaurant husban...          1\n",
       "4       4  wander soho drizzly cold summer day really aug...          1"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import getcwd, chdir\n",
    "import re\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.metrics import ConfusionMatrix\n",
    "from nltk.classify import NaiveBayesClassifier, MaxentClassifier\n",
    "from nltk.classify import accuracy\n",
    "from nltk.tokenize import word_tokenize as wt\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Change your path here\n",
    "fpath = getcwd()\n",
    "print(fpath)\n",
    "\n",
    "def classification_report_csv(report, csv_name):\n",
    "    report_data = []\n",
    "    lines = report.split('\\n')\n",
    "    for line in lines[2:-3]:\n",
    "        row = {}\n",
    "        row_data = line.split(' ') \n",
    "        row_data = list(filter(None, row_data))\n",
    "        row['class'] = row_data[0]\n",
    "        row['precision'] = float(row_data[1])\n",
    "        row['recall'] = float(row_data[2])\n",
    "        row['f1_score'] = float(row_data[3])\n",
    "        row['support'] = float(row_data[4])\n",
    "        report_data.append(row)\n",
    "    dataframe = pd.DataFrame.from_dict(report_data)\n",
    "    dataframe.to_csv(csv_name, index = False)\n",
    "    \n",
    "# Just Scraped Data\n",
    "df_train= pd.read_csv('./data/df_preprocessing_scraped.csv')\n",
    "print(df_train.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26074, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>young day lunch choice consist sohos wide rang...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>go yelp tripadvisor want try chinese restauran...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>order sichuan prawn singapore rice noodle amaz...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>wong kei many option youll find heart london c...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>bad experience restaurant life food service fr...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                             review  sentiment\n",
       "0       5  young day lunch choice consist sohos wide rang...          1\n",
       "1       3  go yelp tripadvisor want try chinese restauran...         -1\n",
       "2       5  order sichuan prawn singapore rice noodle amaz...          1\n",
       "3       3  wong kei many option youll find heart london c...         -1\n",
       "4       1  bad experience restaurant life food service fr...         -1"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combined Data\n",
    "df_train_all = pd.read_csv('./data/df_preprocessing_combined.csv')\n",
    "print(df_train_all.shape)\n",
    "df_train_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dictionary format because apparently NLTK requires this\n",
    "train_pos = [[row[\"review\"], 1] for idx, row in df_train.iterrows() if row[\"sentiment\"]==1]\n",
    "train_neg = [[row[\"review\"], -1] for idx, row in df_train.iterrows() if row[\"sentiment\"]==-1]\n",
    "\n",
    "def word_feats(words):\n",
    "    return dict([(word, True) for word in words])\n",
    "\n",
    "# need this part for max ent portion\n",
    "trainset = train_pos + train_neg\n",
    "train_tokenized = [[wt(x), c] for x,c in trainset] # may need to introduce some pre-processing at this stage for better results\n",
    "train_featureset = [(word_feats(d), c) for (d,c) in train_tokenized] \n",
    "\n",
    "train_all_pos = [[row[\"review\"], 1] for idx, row in df_train_all.iterrows() if row[\"sentiment\"]==1]\n",
    "train_all_neg = [[row[\"review\"], -1] for idx, row in df_train_all.iterrows() if row[\"sentiment\"]==-1]\n",
    "trainset_all = train_all_pos + train_all_neg\n",
    "# train_all_tokenized = [[wt(x), c] for x,c in trainset_all] # may need to introduce some pre-processing at this stage for better results\n",
    "# train_all_featureset = [(word_feats(d), c) for (d,c) in train_all_tokenized] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wt(trainset_all[1][0])\n",
    "train_all_tokenized = []\n",
    "for x,c in trainset_all:\n",
    "    train_all_tokenized.append([wt(str(x)), c])\n",
    "    \n",
    "#train_all_tokenized = [[wt(x), c] for x,c in trainset_all] # may need to introduce some pre-processing at this stage for better results\n",
    "train_all_featureset = [(word_feats(d), c) for (d,c) in train_all_tokenized] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes, Just Scraped Data, Top 10 Most Informative Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                mediocre = True               -1 : 1      =     20.2 : 1.0\n",
      "           disappointing = True               -1 : 1      =     14.7 : 1.0\n",
      "           underwhelming = True               -1 : 1      =     13.7 : 1.0\n",
      "                shouldnt = True               -1 : 1      =     13.0 : 1.0\n",
      "                terrible = True               -1 : 1      =     12.8 : 1.0\n",
      "                   awful = True               -1 : 1      =     12.2 : 1.0\n",
      "                   worst = True               -1 : 1      =     11.7 : 1.0\n",
      "               tasteless = True               -1 : 1      =     11.7 : 1.0\n",
      "                 improve = True               -1 : 1      =     10.3 : 1.0\n",
      "                   count = True               -1 : 1      =     10.3 : 1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred</th>\n",
       "      <th>-1</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actuals</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>1156</td>\n",
       "      <td>141</td>\n",
       "      <td>1297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>163</td>\n",
       "      <td>1134</td>\n",
       "      <td>1297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>1319</td>\n",
       "      <td>1275</td>\n",
       "      <td>2594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred       -1     1   All\n",
       "actuals                  \n",
       "-1       1156   141  1297\n",
       "1         163  1134  1297\n",
       "All      1319  1275  2594"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Naive Bayes Rule using nltk\n",
    "classifier_nb = NaiveBayesClassifier.train(train_featureset)\n",
    "#print(\"Accuracy :\" +str(accuracy(classifier_nb, test_featureset)))\n",
    "classifier_nb.show_most_informative_features(10)\n",
    "\n",
    "## Preparing the data first \n",
    "train_nolab = [t[0] for t in trainset]\n",
    "train_lab = [t[1] for t in trainset]\n",
    "\n",
    "# Create your tf-idf function\n",
    "vectorizer = TfidfVectorizer(max_df=0.7, min_df=3, use_idf=True) # modified this\n",
    "train_vectors = vectorizer.fit_transform(train_nolab)\n",
    "pk.dump(vectorizer, open(\"./models/vectorise_scraped.pk\",\"wb\"))\n",
    "\n",
    "## train Naive Bayes Rule using sklearn\n",
    "clf = MultinomialNB().fit(train_vectors, train_lab)\n",
    "pk.dump(clf, open(\"./models/classifier_scraped_naivebayes.pk\",\"wb\"))\n",
    "predNB = clf.predict(train_vectors)\n",
    "pred = list(predNB)\n",
    "cm1=pd.crosstab( pd.Series(train_lab), pd.Series(pred), rownames= ['actuals'], colnames=['pred'],margins=True)\n",
    "cm1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.89      0.88      0.88      1319\n",
      "          1       0.87      0.89      0.88      1275\n",
      "\n",
      "avg / total       0.88      0.88      0.88      2594\n",
      "\n",
      "0.8828064764841943\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(pred,  train_lab))\n",
    "print (accuracy_score(pred, train_lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(cm1).to_csv('naive_bayes_scraped.csv')\n",
    "report = classification_report(pred, train_lab)\n",
    "classification_report_csv(report, 'naive_bayes_scraped_report.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_result = pd.Series(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier Using Combined Training Set, Top 10 Most Informative Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'young day lunch choice consist sohos wide range eatery oppose today regiment pack lunch spot consistent favourite wong kei even long day work follow lengthy meeting beer decide revisit favourite old haunt good ever order standard ho fun beef scramble egg dish sum love restaurant hearty authentic homestyle cook fill budget fine ingredient simplicity nothing fancy plate wet noodle generous help tender beef egg taste mildly salty slight spring onion sweetness isnt much else get however sense warmth comfort bite place offer price point wong kei long infamous abrasive staff unassuming environment thing problem personally dish provide care way feed way encapsulate chinese way express love word many people appreciate open notice thing place forever love place hope stay forever little pro tip consume eat make use plentiful chilli oil crucial dish rarest perk today standard free tea wong kei please dont change'"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "trainall_nolab = [str(t[0]) for t in trainset_all]\n",
    "trainall_lab = [t[1] for t in trainset_all]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "               brazilian = True               -1 : 1      =     56.0 : 1.0\n",
      "              flavorless = True               -1 : 1      =     52.4 : 1.0\n",
      "            unacceptable = True               -1 : 1      =     44.4 : 1.0\n",
      "                  rudely = True               -1 : 1      =     40.8 : 1.0\n",
      "                     ugh = True               -1 : 1      =     36.5 : 1.0\n",
      "                 roomali = True                1 : -1     =     31.1 : 1.0\n",
      "                downhill = True               -1 : 1      =     28.0 : 1.0\n",
      "                    bleh = True               -1 : 1      =     27.1 : 1.0\n",
      "                 disgust = True               -1 : 1      =     25.5 : 1.0\n",
      "                   worst = True               -1 : 1      =     24.3 : 1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred</th>\n",
       "      <th>-1</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actuals</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>10662</td>\n",
       "      <td>1852</td>\n",
       "      <td>12514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1175</td>\n",
       "      <td>12385</td>\n",
       "      <td>13560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>11837</td>\n",
       "      <td>14237</td>\n",
       "      <td>26074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred        -1      1    All\n",
       "actuals                     \n",
       "-1       10662   1852  12514\n",
       "1         1175  12385  13560\n",
       "All      11837  14237  26074"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Naive Bayes Rule using nltk\n",
    "classifier_nb = NaiveBayesClassifier.train(train_all_featureset)\n",
    "#print(\"Accuracy :\" +str(accuracy(classifier_nb, test_featureset)))\n",
    "classifier_nb.show_most_informative_features(10)\n",
    "\n",
    "\n",
    "\n",
    "# Create your tf-idf function\n",
    "vectorizer_all = TfidfVectorizer(max_df=0.7, min_df=3, use_idf=True) # modified this\n",
    "trainall_vectors = vectorizer_all.fit_transform(trainall_nolab)\n",
    "pk.dump(vectorizer_all, open(\"./models/vectorise_combined.pk\",\"wb\"))\n",
    "\n",
    "## train Naive Bayes Rule using sklearn\n",
    "clf = MultinomialNB().fit(trainall_vectors, trainall_lab)\n",
    "pk.dump(clf, open(\"./models/classifier_combined_naivebayes.pk\",\"wb\"))\n",
    "predNB = clf.predict(trainall_vectors)\n",
    "pred = list(predNB)\n",
    "cm1=pd.crosstab( pd.Series(trainall_lab), pd.Series(pred), rownames= ['actuals'], colnames=['pred'],margins=True)\n",
    "cm1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.85      0.90      0.88     11837\n",
      "          1       0.91      0.87      0.89     14237\n",
      "\n",
      "avg / total       0.89      0.88      0.88     26074\n",
      "\n",
      "0.8839073406458541\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(pred,  trainall_lab))\n",
    "print (accuracy_score(pred, trainall_lab))\n",
    "\n",
    "nb_result_all = pd.Series(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train_all = pd.concat([df_train_all, pd.Series(pred)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(cm1).to_csv('naive_bayes_combined.csv')\n",
    "report = classification_report(pred, trainall_lab)\n",
    "classification_report_csv(report, 'naive_bayes_combined_report.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred</th>\n",
       "      <th>-1</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actuals</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>1291</td>\n",
       "      <td>6</td>\n",
       "      <td>1297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>1286</td>\n",
       "      <td>1297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>1302</td>\n",
       "      <td>1292</td>\n",
       "      <td>2594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred       -1     1   All\n",
       "actuals                  \n",
       "-1       1291     6  1297\n",
       "1          11  1286  1297\n",
       "All      1302  1292  2594"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# SVM Classifier from sklearn\n",
    "def train_svm(X, y):\n",
    "    \"\"\"\n",
    "    Create and train the Support Vector Machine.\n",
    "    \"\"\"\n",
    "    svm = SVC(C=10000.0, gamma='auto', kernel='rbf')\n",
    "    svm.fit(X, y)\n",
    "    return svm\n",
    "\n",
    "classifier_svm = train_svm(train_vectors, train_lab)  # training the SVM model\n",
    "pk.dump(classifier_svm, open(\"./models/classifier_scraped_svm.pk\",\"wb\"))\n",
    "predSVM = classifier_svm.predict(train_vectors) \n",
    "cm1=pd.crosstab( pd.Series(train_lab), pd.Series(predSVM), rownames= ['actuals'], colnames=['pred'],margins=True)\n",
    "cm1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       1.00      0.99      0.99      1302\n",
      "          1       0.99      1.00      0.99      1292\n",
      "\n",
      "avg / total       0.99      0.99      0.99      2594\n",
      "\n",
      "0.9934464148033925\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(predSVM,  train_lab))\n",
    "print (accuracy_score(predSVM, train_lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(cm1).to_csv('svm_scraped.csv')\n",
    "report = classification_report(predSVM, train_lab)\n",
    "classification_report_csv(report, 'svm_scraped_report.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_result = pd.Series(predSVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat SVM Classifier using Combined Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred</th>\n",
       "      <th>-1</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actuals</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>11515</td>\n",
       "      <td>999</td>\n",
       "      <td>12514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>705</td>\n",
       "      <td>12855</td>\n",
       "      <td>13560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>12220</td>\n",
       "      <td>13854</td>\n",
       "      <td>26074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred        -1      1    All\n",
       "actuals                     \n",
       "-1       11515    999  12514\n",
       "1          705  12855  13560\n",
       "All      12220  13854  26074"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_svm = train_svm(trainall_vectors, trainall_lab)  # training the SVM model\n",
    "pk.dump(classifier_svm, open(\"./models/classifier_combined_svm.pk\",\"wb\"))\n",
    "predSVM = classifier_svm.predict(trainall_vectors) \n",
    "cm1=pd.crosstab( pd.Series(trainall_lab), pd.Series(predSVM), rownames= ['actuals'], colnames=['pred'],margins=True)\n",
    "cm1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.92      0.94      0.93     12220\n",
      "          1       0.95      0.93      0.94     13854\n",
      "\n",
      "avg / total       0.93      0.93      0.93     26074\n",
      "\n",
      "0.9346475416123341\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(predSVM,  trainall_lab))\n",
    "print (accuracy_score(predSVM, trainall_lab))\n",
    "svm_result_all = pd.Series(predSVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(cm1).to_csv('svm_scraped_combined.csv')\n",
    "report = classification_report(predSVM, trainall_lab)\n",
    "classification_report_csv(report, 'svm_scraped_combined_report.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.concat([pd.Series(train_lab), nb_result, svm_result], keys=[\"actual\", \"nb\", \"svm\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>nb_combined</th>\n",
       "      <th>svm_combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   actual  nb_combined  svm_combined\n",
       "0       1            1             1\n",
       "1       1            1             1\n",
       "2       1           -1            -1\n",
       "3       1            1             1\n",
       "4       1            1             1"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result_all = pd.concat([pd.Series(trainall_lab), nb_result_all, svm_result_all], keys=[\"actual\", \"nb_combined\", \"svm_combined\"], axis=1)\n",
    "df_result_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_all.to_csv('combined_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv('result.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After pre-processing, we saw some improvement in the results. \n",
    "We decided to use these models to test on the test data. \n",
    "\n",
    "Note that the scraped data has much less data, and it was able to get a good accuracy. \n",
    "Doing predictions for a larger set of data, the combined data gave a lower accuracy.\n",
    "We will run both these models against the test data as we feel that there is a possibility that the combined data model is more generalized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
