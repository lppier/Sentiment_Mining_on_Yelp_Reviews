{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Yelp Sentiment Mining using RNN (LSTM).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "AZcn7LKStNko",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Yelp Sentiment Mining using RNN (LSTM)\n",
        "\n",
        "## Note: Please run this code in Google Colaboratory!!!\n",
        "\n",
        "### How to Run this code\n",
        "1. Upload this notebook to Google Drive\n",
        "2. Create a directory called \"Sentiment_Mining_CA_Data\" and upload \"train.csv\", \"df_reviews_train.csv\" and \"df_reviews_test.csv\"  to that directory.\n",
        "3. Run this notebook using Google Colaboratory."
      ]
    },
    {
      "metadata": {
        "id": "RREn6iHds7GD",
        "colab_type": "code",
        "outputId": "483040d7-45a5-4e0b-b19a-beb8d08605a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install torch==0.4.1 torchvision==0.2.1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==0.4.1 in /usr/local/lib/python3.6/dist-packages (0.4.1)\n",
            "Requirement already satisfied: torchvision==0.2.1 in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.1) (1.11.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.1) (5.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.1) (1.14.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7HdOBdhAwrtZ",
        "colab_type": "code",
        "outputId": "1e6470c8-3bbe-4611-8e33-ca12cb546fa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install torchtext==0.3.1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchtext==0.3.1 in /usr/local/lib/python3.6/dist-packages (0.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.3.1) (2.18.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.3.1) (0.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.3.1) (1.14.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.3.1) (4.27.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.3.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.3.1) (1.22)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.3.1) (2.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.3.1) (2018.10.15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4lo0TUwy1NuQ",
        "colab_type": "code",
        "outputId": "c3452f0b-413d-4338-dd90-4ae9966eabf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install gensim==3.6.0\n",
        "!pip install -U -q PyDrive"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim==3.6.0 in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim==3.6.0) (0.19.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim==3.6.0) (1.11.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim==3.6.0) (1.14.6)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim==3.6.0) (1.7.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim==3.6.0) (1.9.28)\n",
            "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim==3.6.0) (0.98)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim==3.6.0) (2.49.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim==3.6.0) (2.18.4)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim==3.6.0) (0.9.3)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.28 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim==3.6.0) (1.12.28)\n",
            "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim==3.6.0) (0.1.13)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim==3.6.0) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim==3.6.0) (2.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim==3.6.0) (2018.10.15)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim==3.6.0) (1.22)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.28->boto3->smart-open>=1.2.1->gensim==3.6.0) (2.5.3)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.28->boto3->smart-open>=1.2.1->gensim==3.6.0) (0.14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dxiZ98_vw8ih",
        "colab_type": "code",
        "outputId": "2f5b6872-b5ca-4c43-aed2-ea7040f17931",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "cell_type": "code",
      "source": [
        "!python -m spacy download en"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "\n",
            "    You can now load the model via spacy.load('en')\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OFM3ndSx2Fhw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7E0bZBkz4LaZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# download google drive file\n",
        "def download_drive_file(drive_directory, filename):\n",
        "  list_file_query = \"title='{}' and trashed=false\".format(drive_directory)\n",
        "  file_list = drive.ListFile({'q': list_file_query}).GetList()\n",
        "\n",
        "  if len(file_list) > 0:\n",
        "    directory_id = file_list[0]['id']\n",
        "\n",
        "    list_file_query = \"'{}' in parents\".format(directory_id)\n",
        "\n",
        "    file_list = drive.ListFile({'q': list_file_query}).GetList()\n",
        "    \n",
        "    file_id = None\n",
        "    for file1 in file_list:\n",
        "      if file1['title'] == filename:\n",
        "        print(\"downloading file {}\".format(file1['title']))\n",
        "        file1.GetContentFile(file1['title'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J1JPJ0hn5Nys",
        "colab_type": "code",
        "outputId": "5dfb362b-5828-4f9c-9508-9ee79cfcfcd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "download_drive_file(\"Sentiment_Mining_CA_Data\", \"train.csv\")\n",
        "download_drive_file(\"Sentiment_Mining_CA_Data\", \"df_reviews_train.csv\")\n",
        "download_drive_file(\"Sentiment_Mining_CA_Data\", \"df_reviews_test.csv\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading file train.csv\n",
            "downloading file df_reviews_train.csv\n",
            "downloading file df_reviews_test.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nIF6lyFNU2VA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d57c09ce-3574-47e6-bffc-a56648e33790"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_standard = pd.read_csv(\"train.csv\", encoding=\"ISO-8859-1\")\n",
        "df_standard.head(5)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>restaurant_id</th>\n",
              "      <th>date</th>\n",
              "      <th>review_id</th>\n",
              "      <th>stars</th>\n",
              "      <th>text</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tr1</td>\n",
              "      <td>3/13/2014</td>\n",
              "      <td>revtrain1</td>\n",
              "      <td>2</td>\n",
              "      <td>Very disappointed in the customer service. We ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tr2</td>\n",
              "      <td>7/15/2010</td>\n",
              "      <td>revtrain2</td>\n",
              "      <td>2</td>\n",
              "      <td>I really wasn't thrilled with our meal here. T...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tr2</td>\n",
              "      <td>12/20/2010</td>\n",
              "      <td>revtrain3</td>\n",
              "      <td>1</td>\n",
              "      <td>STAY AWAY...\\n\\nWe've been 3 times over the pa...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tr2</td>\n",
              "      <td>5/26/2011</td>\n",
              "      <td>revtrain4</td>\n",
              "      <td>2</td>\n",
              "      <td>The food is good and the portions are large.  ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tr2</td>\n",
              "      <td>6/22/2011</td>\n",
              "      <td>revtrain5</td>\n",
              "      <td>2</td>\n",
              "      <td>I feel bad about giving this place such a meh ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  restaurant_id        date  review_id  stars  \\\n",
              "0           tr1   3/13/2014  revtrain1      2   \n",
              "1           tr2   7/15/2010  revtrain2      2   \n",
              "2           tr2  12/20/2010  revtrain3      1   \n",
              "3           tr2   5/26/2011  revtrain4      2   \n",
              "4           tr2   6/22/2011  revtrain5      2   \n",
              "\n",
              "                                                text Sentiment  \n",
              "0  Very disappointed in the customer service. We ...  negative  \n",
              "1  I really wasn't thrilled with our meal here. T...  negative  \n",
              "2  STAY AWAY...\\n\\nWe've been 3 times over the pa...  negative  \n",
              "3  The food is good and the portions are large.  ...  negative  \n",
              "4  I feel bad about giving this place such a meh ...  negative  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "yDJR4iM4Xy_H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0d339522-4b8e-49b3-bad3-63df91872c97"
      },
      "cell_type": "code",
      "source": [
        "df_standard[\"review\"] = df_standard[\"text\"]\n",
        "df_standard[\"sentiment\"] = df_standard[\"Sentiment\"].apply(lambda x: -1 if x == \"negative\" else 1)\n",
        "df_standard = df_standard[[\"review\", \"sentiment\"]]\n",
        "df_standard.head(5)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Very disappointed in the customer service. We ...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I really wasn't thrilled with our meal here. T...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>STAY AWAY...\\n\\nWe've been 3 times over the pa...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The food is good and the portions are large.  ...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I feel bad about giving this place such a meh ...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  sentiment\n",
              "0  Very disappointed in the customer service. We ...         -1\n",
              "1  I really wasn't thrilled with our meal here. T...         -1\n",
              "2  STAY AWAY...\\n\\nWe've been 3 times over the pa...         -1\n",
              "3  The food is good and the portions are large.  ...         -1\n",
              "4  I feel bad about giving this place such a meh ...         -1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "HtuzjRDPZduU",
        "colab_type": "code",
        "outputId": "b18e7fe0-ab6c-4323-95be-30fa0487d7d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_train = pd.read_csv(\"df_reviews_train.csv\")\n",
        "df_train.head(5)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>In my younger days when lunch choices consiste...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>After going through yelp and tripadvisor, I wa...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>Ordered Sichuan Prawns and Singapore Rice Nood...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Wong Kei is one of the many options you'll fin...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>One of the worst experience in a restaurant in...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   rating                                             review  sentiment\n",
              "0       5  In my younger days when lunch choices consiste...          1\n",
              "1       3  After going through yelp and tripadvisor, I wa...         -1\n",
              "2       5  Ordered Sichuan Prawns and Singapore Rice Nood...          1\n",
              "3       3  Wong Kei is one of the many options you'll fin...         -1\n",
              "4       1  One of the worst experience in a restaurant in...         -1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "gtj7tkmCYckS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4dc37c43-83de-4598-9f93-1d4dbba96568"
      },
      "cell_type": "code",
      "source": [
        "df_train = df_train[[\"review\", \"sentiment\"]]\n",
        "df_train = pd.concat([df_train, df_standard], axis=0)\n",
        "df_train.to_csv(\"df_train.csv\", encoding=\"utf-8\", index=False)\n",
        "df_train.head(5)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In my younger days when lunch choices consiste...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>After going through yelp and tripadvisor, I wa...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ordered Sichuan Prawns and Singapore Rice Nood...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Wong Kei is one of the many options you'll fin...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>One of the worst experience in a restaurant in...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  sentiment\n",
              "0  In my younger days when lunch choices consiste...          1\n",
              "1  After going through yelp and tripadvisor, I wa...         -1\n",
              "2  Ordered Sichuan Prawns and Singapore Rice Nood...          1\n",
              "3  Wong Kei is one of the many options you'll fin...         -1\n",
              "4  One of the worst experience in a restaurant in...         -1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "_XuoQikOgLTc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "420bc3b8-1b03-45d2-b5de-d2a6f5e61b41"
      },
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv(\"df_reviews_test.csv\")\n",
        "df_test.head(5)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>Let's be real here...London...and noodles?? Ye...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>Who goes to London and has Chinese food? Me of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>My family and I visited London for a few days ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>This place is so unassuming and very easy to p...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>It's a small and cramped little hole in the wa...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   rating                                             review  sentiment\n",
              "0       5  Let's be real here...London...and noodles?? Ye...          1\n",
              "1       5  Who goes to London and has Chinese food? Me of...          1\n",
              "2       5  My family and I visited London for a few days ...          1\n",
              "3       5  This place is so unassuming and very easy to p...          1\n",
              "4       3  It's a small and cramped little hole in the wa...         -1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "qrBnhHV2gPrY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "915e0784-e131-474b-d518-80431aaafb07"
      },
      "cell_type": "code",
      "source": [
        "df_test[[\"review\", \"sentiment\"]].to_csv(\"df_test.csv\", encoding=\"utf-8\", index=False)\n",
        "df_test = pd.read_csv(\"df_test.csv\")\n",
        "df_test.head(5)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Let's be real here...London...and noodles?? Ye...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Who goes to London and has Chinese food? Me of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>My family and I visited London for a few days ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This place is so unassuming and very easy to p...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>It's a small and cramped little hole in the wa...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  sentiment\n",
              "0  Let's be real here...London...and noodles?? Ye...          1\n",
              "1  Who goes to London and has Chinese food? Me of...          1\n",
              "2  My family and I visited London for a few days ...          1\n",
              "3  This place is so unassuming and very easy to p...          1\n",
              "4  It's a small and cramped little hole in the wa...         -1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "Naw-NDherS7I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preparing Data\n",
        "\n",
        "The same as before, we'll set the seed, define the Fields and get the train/valid/test splits."
      ]
    },
    {
      "metadata": {
        "id": "XiQUTI1frS7K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "\n",
        "TEXT = data.Field(tokenize='spacy')\n",
        "LABEL = data.LabelField(is_target=True, dtype=torch.float)\n",
        "\n",
        "train_pos = data.TabularDataset(\n",
        "    path='df_train.csv', format='csv',\n",
        "    skip_header=True,\n",
        "    fields=[\n",
        "        ('text', TEXT), \n",
        "        ('label', LABEL)\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "test_data = data.TabularDataset(\n",
        "    path='df_test.csv', format='csv', \n",
        "    skip_header=True,\n",
        "    fields=[\n",
        "        ('text', TEXT), \n",
        "        ('label', LABEL)\n",
        "    ]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W7RCIYIAXZQF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "train_data, valid_data = train_pos.split(split_ratio=0.8, stratified=False, strata_field='label', random_state=random.seed(SEED))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VPEjy1xJrS7Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can see how many examples are in each split by checking their length."
      ]
    },
    {
      "metadata": {
        "id": "GknAU6ohrS7Y",
        "colab_type": "code",
        "outputId": "ee75c87b-49b9-48f5-b824-cb74d4aa621a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "print('len(train_data):', len(train_data))\n",
        "print('len(valid_data):', len(valid_data))\n",
        "print('len(test_data):', len(test_data))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "len(train_data): 20859\n",
            "len(valid_data): 5215\n",
            "len(test_data): 3551\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Q7dW09-SrS7b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can check the fields of the data, hoping that it they match the Fields given earlier."
      ]
    },
    {
      "metadata": {
        "id": "VdFO88SfrS7c",
        "colab_type": "code",
        "outputId": "6d2df8fa-5988-45eb-b65e-3c309f79503f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "print('train_data.fields:', train_data.fields)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_data.fields: {'text': <torchtext.data.field.Field object at 0x7fd9a9ae2630>, 'label': <torchtext.data.field.LabelField object at 0x7fd9a9ae2668>}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Nmjw2H28rS7e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can also check an example."
      ]
    },
    {
      "metadata": {
        "id": "a-z-M4MFrS7e",
        "colab_type": "code",
        "outputId": "b9f856b5-73df-40c8-e2cd-1b20d0d25978",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "print('vars(train_data[0]):', vars(train_data[0]))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vars(train_data[0]): {'text': ['Lunch', 'here', 'is', 'great', '!', ' ', 'Nice', '\"', 'patio', '\"', 'in', 'front', 'to', 'eat', 'in', 'when', 'the', 'weather', 'is', 'beautiful', '!', ' ', 'The', 'bread', ',', 'to', 'die', 'for', '!', ' ', 'Nice', 'lunch', 'spot', 'for', 'pizza', 'and', 'a', 'salad', '!'], 'label': '1'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "26e3b3xlY4N9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The first update, is the addition of pre-trained word embeddings. These vectors have been trained on corpuses of billions of tokens. Now, instead of having our word embeddings initialized randomly, they are initialized with these pre-trained vectors, where words that appear in similar contexts appear nearby in this vector space.\n",
        "The first step to using these is to specify the vectors and download them, which is passed as an argument to build_vocab. The glove is the algorithm used to calculate the vectors, go here for more. 6B indicates these vectors were trained on 6 billion tokens. 100d indicates these vectors are 100-dimensional.\n",
        "Note: these vectors are about 862MB, so watch out if you have a limited internet connection."
      ]
    },
    {
      "metadata": {
        "id": "WwpEQ5GyY2d2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a3dc805b-ddc8-4f21-cb4a-67d27de8901d"
      },
      "cell_type": "code",
      "source": [
        "TEXT.build_vocab(train_data, max_size=50000, vectors=\"glove.6B.100d\")\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:37, 5.49MB/s]                           \n",
            "100%|█████████▉| 399317/400000 [00:19<00:00, 20138.90it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "qo9pQwevrS7s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As before, we create the iterators."
      ]
    },
    {
      "metadata": {
        "id": "EFiVT5I9rS7t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size=BATCH_SIZE, \n",
        "    sort_key=lambda x: len(x.text), \n",
        "    repeat=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R96B8UBVrS7u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Build the Model\n",
        "\n",
        "The model features the most drastic changes.\n",
        "\n",
        "### Different RNN Architecture\n",
        "\n",
        "We use a different RNN architecture called a Long Short-Term Memory (LSTM). Why is an LSTM better than a standard RNN? The hidden state can be thought of as a \"memory\" of the words seen by the model. It is difficult to train a standard RNN as the gradient decays exponentially along the sequence, causing the RNN to \"forget\" what has happened earlier in the sequence. LSTMs have an extra recurrent state called a cell, which can be thought of as the \"memory\" of the LSTM and can remember information for many time steps. LSTMs also use multiple gates, these control the flow of information into and out of the memory. For more information, go [here](https://colah.github.io/posts/2015-08-Understanding-LSTMs/).\n",
        "\n",
        "### Bidirectional RNN\n",
        "\n",
        "The concept behind a bidirectional RNN is simple. As well as having an RNN processing the words in the sentence from the first to the last, we have a second RNN processing the words in the sentence from **the last to the first**. PyTorch simplifies this by concatenating both the forward and backward RNNs together, and thus the returned final hidden state, hidden, is the concatenation of the hidden state from the last word of the sentence from the forward RNN with the hidden state of the first word of the sentence from the backward RNN, both of which are the final hidden states from their respective RNNs.\n",
        "\n",
        "![](https://camo.githubusercontent.com/9f462fe904900e9fc30a10101df3884fec700f60/68747470733a2f2f692e696d6775722e636f6d2f69746d494967782e706e67)\n",
        "\n",
        "### Multi-layer RNN\n",
        "\n",
        "Multi-layer RNNs (also called deep RNNs) are another simple concept. The idea is that we add additional RNNs on top of the initial standard RNN, where each RNN added is another layer. The hidden state output by the first (bottom) RNN at time-step $t$ will be the input to the RNN above it at time step $t$. The prediction is then usually made from the final hidden state of the final (highest) layer. These are easily combined with bi-directional RNNs, where each extra layer adds an additional forward and backward RNN.\n",
        "\n",
        "![](https://camo.githubusercontent.com/0b711a2cae89c6b6bc3cc9e57a95d4f047d2116f/68747470733a2f2f692e696d6775722e636f6d2f6b6e73497a65682e706e67)\n",
        "\n",
        "### Regularization\n",
        "\n",
        "Although we've added improvements to our model, each one adds additional parameters. Without going into overfitting into to much detail, the more parameters you have in in your model, the higher the probability that you'll overfit (have a low train error but high validation/test error). To combat this, we use regularization. More specifically, we use a method of regularization called dropout. Dropout works by randomly dropping out (setting to 0) neurons during a forward pass. The probability that each neuron is dropped out is set by a hyperparameter and each neuron with dropout applied is considered indepenently. One theory about why dropout works is that a model with parameters dropped out can be seen as a \"weaker\" (less parameters) model, the predictions from all these \"weaker\" models (one for each forward pass) get averaged together in the parameters of the model. Thus, your one model can be thought of as an ensemble of weaker models, none of which are over-parameterized and thus should not overfit.\n",
        "\n",
        "### Implementation Details\n",
        "\n",
        "To use an LSTM instead of the standard RNN, we use nn.LSTM instead of nn.RNN on line 8. Also note on line 20 the LSTM returns the output and a tuple of the final hidden state and the final cell state, whereas the standard RNN only returned the output and final hidden state.\n",
        "\n",
        "As the final hidden state of our LSTM has both a forward and a backward component, which are concatenated together, the size of the input to the nn.Linear layer is twice that of the hidden dimension size.\n",
        "\n",
        "Implementing bidirectionality and adding additional layers are done by passing values for the num_layers and bidirectional arguments for the RNN/LSTM.\n",
        "\n",
        "Dropout is implemented by initializing an nn.Dropout layer (the argument is the probability of dropout for each neuron) and using it within the forward method after each layer we want to apply dropout to. Note: never use dropout on the input or output layers (x or fc in this case), you only ever want to use dropout on intermediate layers. The LSTM has a dropout argument which adds dropout on the connections between hidden states in one layer to hidden states in the next layer."
      ]
    },
    {
      "metadata": {
        "id": "18zc0D2KrS7v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=bidirectional, dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_dim*2, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        #x = [sent len, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(x))\n",
        "        \n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "        output, (hidden, cell) = self.rnn(embedded)\n",
        "        \n",
        "        #output = [sent len, batch size, hid dim * num directions]\n",
        "        #hidden = [num layers * num directions, batch size, hid. dim]\n",
        "        #cell = [num layers * num directions, batch size, hid. dim]\n",
        "        \n",
        "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n",
        "                \n",
        "        #hidden [batch size, hid. dim * num directions]\n",
        "            \n",
        "        return self.fc(hidden.squeeze(0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bq4FY1eurS7w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Like before, we'll create an instance of our RNN class, with the new parameters and arguments for the number of layers, bidirectionality and dropout probability.\n",
        "To ensure the pre-trained vectors can be loaded into the model, the EMBEDDING_DIM must be equal to that of the pre-trained GloVe vectors loaded earlier."
      ]
    },
    {
      "metadata": {
        "id": "uD8-4kS3rS7x",
        "colab_type": "code",
        "outputId": "f9e6195d-b4cb-4e72-c511-7f862b9f60f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "print(\"Input dimension:\", INPUT_DIM)\n",
        "\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.5\n",
        "\n",
        "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, BIDIRECTIONAL, DROPOUT)\n",
        "print(model)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input dimension: 50002\n",
            "RNN(\n",
            "  (embedding): Embedding(50002, 100)\n",
            "  (rnn): LSTM(100, 256, num_layers=2, dropout=0.5, bidirectional=True)\n",
            "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.5)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dstSKG2Mcsya",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The final addition is copying the pre-trained word embeddings we loaded earlier into the embedding layer of our model.\n",
        "\n",
        "We retrieve the embeddings from the field's vocab, and ensure they're the correct size, **[vocab size, embedding dim]**"
      ]
    },
    {
      "metadata": {
        "id": "FKnJc3SEcy70",
        "colab_type": "code",
        "outputId": "542401bb-eb28-46a2-8843-ca4dfd2a3b08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "\n",
        "print(pretrained_embeddings.shape)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([50002, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wNaqaZQCc2Jf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We then replace the initial weights of the embedding layer with the pre-trained embeddings."
      ]
    },
    {
      "metadata": {
        "id": "7ihCyWpuc56c",
        "colab_type": "code",
        "outputId": "28cb78cf-f565-4e52-b340-1f6c6c6bd453",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [-0.3398,  0.2094,  0.4635,  ..., -0.2339,  0.4730, -0.0288],\n",
              "        ...,\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.7231,  0.8337, -0.1084,  ...,  0.2129,  0.2939, -0.0405],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "L4xDY8CLrS7y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train the Model\n",
        "\n",
        "Now to training the model.\n",
        "\n",
        "The only change we'll make here is changing the optimizer from `SGD` to `Adam`. SGD updates all parameters with the same learning rate and choosing this learning rate can be tricky. Adam adapts the learning rate for each parameter, giving parameters that are updated more frequently lower learning rates and parameters that are updated infrequently higher learning rates. More information about Adam (and other optimizers) can be found [here](http://ruder.io/optimizing-gradient-descent/index.html).\n",
        "\n",
        "To change `SGD` to `Adam`, we simply change `optim.SGD` to `optim.Adam,` also note how we do not have to provide an initial learning rate for Adam as PyTorch specifies a sensibile initial learning rate."
      ]
    },
    {
      "metadata": {
        "id": "etHOvPERrS7z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CNHAtqfwrS70",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The rest of the steps for training the model are unchanged.\n",
        "\n",
        "We define the criterion and place the model and criterion on the GPU (if available)..."
      ]
    },
    {
      "metadata": {
        "id": "zyrfpvctrS71",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b3UefxVyrS73",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We implement the function to calculate accuracy..."
      ]
    },
    {
      "metadata": {
        "id": "h7-a98l_rS73",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum()/len(correct)\n",
        "    return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6vld5loxrS74",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We define a function for training our model...\n",
        "\n",
        "**Note:** as we are now using dropout, we must remember to use `model.train()` to ensure the dropout is \"turned on\" while training."
      ]
    },
    {
      "metadata": {
        "id": "CPdnwRhkrS74",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        predictions = model(batch.text.to(device)).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, batch.label.to(device))\n",
        "        \n",
        "        acc = binary_accuracy(predictions, batch.label.to(device))\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JWaYhAD_rS75",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We define a function for testing our model...\n",
        "\n",
        "**Note:** as we are now using dropout, we must remember to use `model.eval()` to ensure the dropout is \"turned off\" while evaluating."
      ]
    },
    {
      "metadata": {
        "id": "AeLO_teFrS76",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            predictions = model(batch.text.to(device)).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.label.to(device))\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.label.to(device))\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "00SZAY7DrS76",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Finally, we train our model..."
      ]
    },
    {
      "metadata": {
        "id": "LOB6qia4rS77",
        "colab_type": "code",
        "outputId": "87471a0a-e217-447e-e13a-6ec7902655be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02}, Train Loss: {train_loss:.3f}, Train Acc: {train_acc*100:.2f}%, Val. Loss: {valid_loss:.3f}, Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01, Train Loss: 0.620, Train Acc: 65.05%, Val. Loss: 0.478, Val. Acc: 78.61%\n",
            "Epoch: 02, Train Loss: 0.529, Train Acc: 73.52%, Val. Loss: 0.410, Val. Acc: 83.97%\n",
            "Epoch: 03, Train Loss: 0.383, Train Acc: 83.72%, Val. Loss: 0.327, Val. Acc: 87.08%\n",
            "Epoch: 04, Train Loss: 0.273, Train Acc: 89.18%, Val. Loss: 0.287, Val. Acc: 88.68%\n",
            "Epoch: 05, Train Loss: 0.216, Train Acc: 91.75%, Val. Loss: 0.315, Val. Acc: 87.80%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Kxd7wzqZrS78",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "...and get our new and vastly improved test accuracy!"
      ]
    },
    {
      "metadata": {
        "id": "lczIjqZjrS79",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "metadata": {
        "id": "bccQWZhlrS79",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Finally, the metric you actually care about, the test loss and accuracy."
      ]
    },
    {
      "metadata": {
        "id": "V4WI7kR7rS79",
        "colab_type": "code",
        "outputId": "178c360d-e3a8-4374-8bd5-e89a417c90bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f}, Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.297, Test Acc: 87.86%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CzTv6vfBrS7_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def to_binary(preds):\n",
        "    \"\"\"\n",
        "    Convert predicted torch array to either 0 or 1\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    return torch.round(torch.sigmoid(preds))\n",
        "\n",
        "def predict(model, iterator):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    all_predictions = []\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            \n",
        "            predictions = to_binary(model(batch.text.to(device)).squeeze(1)).cpu().numpy()\n",
        "            all_predictions += predictions.tolist()\n",
        "            \n",
        "    return all_predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I4e-9oSGrS8A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is the confusion matrix based on predicted and actual test label."
      ]
    },
    {
      "metadata": {
        "id": "PVny0wu6rS8A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_predicted_labels = predict(model, test_iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-7hBySNjcj8s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import itertools\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "def print_confusion_matrix(confusion_matrix, class_names, figsize = (3.5,3), fontsize=15):\n",
        "    \"\"\"Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\n",
        "    \n",
        "    Arguments\n",
        "    ---------\n",
        "    confusion_matrix: numpy.ndarray\n",
        "        The numpy.ndarray object returned from a call to sklearn.metrics.confusion_matrix. \n",
        "        Similarly constructed ndarrays can also be used.\n",
        "    class_names: list\n",
        "        An ordered list of class names, in the order they index the given confusion matrix.\n",
        "    figsize: tuple\n",
        "        A 2-long tuple, the first value determining the horizontal size of the ouputted figure,\n",
        "        the second determining the vertical size. Defaults to (10,7).\n",
        "    fontsize: int\n",
        "        Font size for axes labels. Defaults to 14.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    matplotlib.figure.Figure\n",
        "        The resulting confusion matrix figure\n",
        "    \"\"\"\n",
        "    df_cm = pd.DataFrame(\n",
        "        confusion_matrix, index=class_names, columns=class_names, \n",
        "    )\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    try:\n",
        "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
        "    except ValueError:\n",
        "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
        "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
        "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    return fig"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eaa5kESArS8C",
        "colab_type": "code",
        "outputId": "9e7e24be-1207-41b1-b8e1-3c80a884f7d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "cell_type": "code",
      "source": [
        "classes = [\"Negative\", \"Positive\"]\n",
        "test_actual_labels = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_iterator:\n",
        "        test_actual_labels += batch.label.cpu().numpy().tolist()\n",
        "        \n",
        "cm = confusion_matrix(test_actual_labels, test_predicted_labels)\n",
        "print(print_confusion_matrix(cm, class_names=classes))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Figure(252x216)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAASoAAAD6CAYAAAAWcwq0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nv9L1AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fd9611272b0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Q6AuFPG7l4LN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for element in np.array(test_actual_labels):\n",
        "  if element > 1:\n",
        "    print(element)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LD_8SpjLH3mT",
        "colab_type": "code",
        "outputId": "848ac5b7-41ee-4488-f875-ec909ac03357",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "cell_type": "code",
      "source": [
        "precision, recall, fscore, support = precision_recall_fscore_support(test_actual_labels, test_predicted_labels)\n",
        "score_dict = {\n",
        "  \"precision\": precision.round(4),\n",
        "  \"recall\": recall.round(4),\n",
        "  \"f1-score\": fscore.round(4),\n",
        "  \"support\": support.round(4)\n",
        "}\n",
        "score_df = pd.DataFrame(score_dict, index=classes)\n",
        "score_df"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f1-score</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Negative</th>\n",
              "      <td>0.9228</td>\n",
              "      <td>0.8947</td>\n",
              "      <td>0.9526</td>\n",
              "      <td>2703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Positive</th>\n",
              "      <td>0.7166</td>\n",
              "      <td>0.8098</td>\n",
              "      <td>0.6427</td>\n",
              "      <td>848</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          f1-score  precision  recall  support\n",
              "Negative    0.9228     0.8947  0.9526     2703\n",
              "Positive    0.7166     0.8098  0.6427      848"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "metadata": {
        "id": "71pSafeRJdJc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Performance score using binary average"
      ]
    },
    {
      "metadata": {
        "id": "YW31cDFYJdRU",
        "colab_type": "code",
        "outputId": "09c55f0a-a317-4390-e73f-be6b852b983d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "cell_type": "code",
      "source": [
        "precision, recall, fscore, support = precision_recall_fscore_support(test_actual_labels, test_predicted_labels, average=\"binary\")\n",
        "score_dict = {\n",
        "  \"precision\": precision.round(4),\n",
        "  \"recall\": recall.round(4),\n",
        "  \"f1-score\": fscore.round(4),\n",
        "  \"support\": support\n",
        "}\n",
        "score_df = pd.DataFrame(score_dict, index=[\"score\"])\n",
        "score_df"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f1-score</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>score</th>\n",
              "      <td>0.7166</td>\n",
              "      <td>0.8098</td>\n",
              "      <td>0.6427</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       f1-score  precision  recall support\n",
              "score    0.7166     0.8098  0.6427    None"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "id": "_7j2uq6iI4F5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Performance score using micro average"
      ]
    },
    {
      "metadata": {
        "id": "L9ORzFnJI3ac",
        "colab_type": "code",
        "outputId": "cb57c066-03bb-4f35-a044-01f97ad71154",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "cell_type": "code",
      "source": [
        "precision, recall, fscore, support = precision_recall_fscore_support(test_actual_labels, test_predicted_labels, average=\"micro\")\n",
        "score_dict = {\n",
        "  \"precision\": precision.round(4),\n",
        "  \"recall\": recall.round(4),\n",
        "  \"f1-score\": fscore.round(4),\n",
        "  \"support\": support\n",
        "}\n",
        "score_df = pd.DataFrame(score_dict, index=[\"score\"])\n",
        "score_df"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f1-score</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>score</th>\n",
              "      <td>0.8786</td>\n",
              "      <td>0.8786</td>\n",
              "      <td>0.8786</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       f1-score  precision  recall support\n",
              "score    0.8786     0.8786  0.8786    None"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "metadata": {
        "id": "QnKk7Bf1I12S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Performance score using macro average"
      ]
    },
    {
      "metadata": {
        "id": "3Ove6a2ZIoVy",
        "colab_type": "code",
        "outputId": "432c146a-7cb7-4f56-eb43-f5dfefbd8f13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "cell_type": "code",
      "source": [
        "precision, recall, fscore, support = precision_recall_fscore_support(test_actual_labels, test_predicted_labels, average=\"macro\")\n",
        "score_dict = {\n",
        "  \"precision\": precision.round(4),\n",
        "  \"recall\": recall.round(4),\n",
        "  \"f1-score\": fscore.round(4),\n",
        "  \"support\": support\n",
        "}\n",
        "score_df = pd.DataFrame(score_dict, index=[\"score\"])\n",
        "score_df"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f1-score</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>score</th>\n",
              "      <td>0.8197</td>\n",
              "      <td>0.8523</td>\n",
              "      <td>0.7977</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       f1-score  precision  recall support\n",
              "score    0.8197     0.8523  0.7977    None"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "metadata": {
        "id": "66fvwy0WJRqB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Performance score using weighted average"
      ]
    },
    {
      "metadata": {
        "id": "CBen1IJIJR4z",
        "colab_type": "code",
        "outputId": "3637d29a-c196-45ae-fb32-1565d80f50c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "cell_type": "code",
      "source": [
        "precision, recall, fscore, support = precision_recall_fscore_support(test_actual_labels, test_predicted_labels, average=\"weighted\")\n",
        "score_dict = {\n",
        "  \"precision\": precision.round(4),\n",
        "  \"recall\": recall.round(4),\n",
        "  \"f1-score\": fscore.round(4),\n",
        "  \"support\": support\n",
        "}\n",
        "score_df = pd.DataFrame(score_dict, index=[\"score\"])\n",
        "score_df"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f1-score</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>score</th>\n",
              "      <td>0.8735</td>\n",
              "      <td>0.8744</td>\n",
              "      <td>0.8786</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       f1-score  precision  recall support\n",
              "score    0.8735     0.8744  0.8786    None"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "id": "yHn-qyeJrS8F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can finally save our upgraded RNN model for IT job classification task."
      ]
    },
    {
      "metadata": {
        "id": "W5UjjdwMrS8G",
        "colab_type": "code",
        "outputId": "b21630bf-90a0-44ce-92d6-142c6c33aa0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "torch.save(model, 'classifier_lstm.pth')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type RNN. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "pJ0Tyqf2jUw1",
        "colab_type": "code",
        "outputId": "4abc819f-62c0-47b6-d1d9-25149f8b1984",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "!ls -lAh"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 97M\n",
            "-rw-r--r-- 1 root root  28M Oct 22 15:54 02_lstm.pth\n",
            "-rw-r--r-- 1 root root 2.5K Oct 22 15:08 adc.json\n",
            "drwxr-xr-x 1 root root 4.0K Oct 22 15:08 .config\n",
            "-rw-r--r-- 1 root root 2.5M Oct 22 15:14 df_reviews_test.csv\n",
            "-rw-r--r-- 1 root root 3.8M Oct 22 15:14 df_reviews_train.csv\n",
            "-rw-r--r-- 1 root root 2.5M Oct 22 15:27 df_test.csv\n",
            "-rw-r--r-- 1 root root  18M Oct 22 15:26 df_train.csv\n",
            "-rw-r--r-- 1 root root  28M Oct 22 15:55 lstm.pth\n",
            "drwxr-xr-x 2 root root 4.0K Oct 18 16:40 sample_data\n",
            "-rw-r--r-- 1 root root  15M Oct 22 15:14 train.csv\n",
            "drwxr-xr-x 2 root root 4.0K Oct 22 15:32 .vector_cache\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OOj-jIVVivVo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('classifier_lstm.pth') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "azWCX0XrrS8H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Next Steps\n",
        "\n",
        "We've now built a decent sentiment analysis model for movie reviews. However, not all of the steps we have added were necessary to achieve the test accuracy we've achieved. In the next notebook we'll implement a model that gets comparable accuracy with far fewer parameters and trains much, much faster."
      ]
    }
  ]
}